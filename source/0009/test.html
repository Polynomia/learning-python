
<!doctype html>
<html lang="zh-CN" class="">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>贺完结！CS231n官方笔记授权翻译总集篇发布 - 知乎专栏</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
    <link rel="shortcut icon" href="https://static.zhihu.com/static/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="//static.zhihu.com/hemingway/app.46736c97107600d59de125d4adee6a8e.css" />
    <style></style>
    <script>document.documentElement.className += ('ontouchstart' in window) ? ' touch' : ' no-touch'</script>
  </head>
  <body>

    <div id="react-root"></div>
    <textarea id="clientConfig" hidden>{"debug":false,"apiRoot":"","paySDK":"https://pay.zhihu.com/api/js","wechatConfigAPI":"/api/wechat/jssdkconfig","name":"production","instance":"column","tokens":{"X-XSRF-TOKEN":"2|36deaf87|57bb97be06ef96e61beccabf06f39be403e782bf0fe7cbaa0fe8ccb050ba9fbf01e89eb3|1501309038","X-UDID":"\"AHCAN3j1wgqPTkGP9jN8h9sVoURReCmOqV0=|1477662159\"","Authorization":["\"2","1:0","10:1499245557","4:z_c0","92:Mi4wQUJETWZNUUY2Z2dBY0lBM2VQWENDaVlBQUFCZ0FsVk45VGlFV1FBaEYyb21DZDF3MGxZcUlsNUxvSVJqbTEwZ3dR","6b4cd7f5488e83e697480066adcb5c8ad2dda225144ec1e3b43d907da2810b83\""]}}</textarea>
    <textarea id="preloadedState" hidden>{"database":{"Post":{"21930884":{"title":"贺完结！CS231n官方笔记授权翻译总集篇发布","author":"du-ke","content":"<blockquote>哈哈哈！我们也是不谦虚，几个“业余水平”的网友，怎么就“零星”地把这件事给搞完了呢！<b>总之就是非常开心</b>，废话不多说，进入正题吧！</blockquote><h2>CS231n简介</h2><p>CS231n的全称是<a href=\"http://link.zhihu.com/?target=http%3A//vision.stanford.edu/teaching/cs231n/index.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">CS231n: Convolutional Neural Networks for Visual Recognition<i class=\"icon-external\"></i></a>，即<b>面向视觉识别的卷积神经网络</b>。该课程是<a href=\"http://link.zhihu.com/?target=http%3A//vision.stanford.edu/index.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">斯坦福大学计算机视觉实验室<i class=\"icon-external\"></i></a>推出的课程。需要注意的是，目前大家说CS231n，大都指的是2016年冬季学期（一月到三月）的最新版本。</p><p><b>课程描述</b>：请允许我们引用课程主页上的<b>官方描述</b>如下。</p><blockquote>计算机视觉在社会中已经逐渐普及，并广泛运用于搜索检索、图像理解、手机应用、地图导航、医疗制药、无人机和无人驾驶汽车等领域。而这些应用的核心技术就是图像分类、图像定位和图像探测等视觉识别任务。近期神经网络（也就是“深度学习”）方法上的进展极大地提升了这些代表当前发展水平的视觉识别系统的性能。<br><br>本课程将深入讲解深度学习框架的细节问题，聚焦面向视觉识别任务（尤其是图像分类任务）的端到端学习模型。在10周的课程中，学生们将会学习如何实现、训练和调试他们自己的神经网络，并建立起对计算机视觉领域的前沿研究方向的细节理解。最终的作业将包括训练一个有几百万参数的卷积神经网络，并将其应用到最大的图像分类数据库（ImageNet）上。我们将会聚焦于教授如何确定图像识别问题，学习算法（比如反向传播算法），对网络的训练和精细调整（fine-tuning）中的工程实践技巧，指导学生动手完成课程作业和最终的课程项目。本课程的大部分背景知识和素材都来源于<a href=\"http://link.zhihu.com/?target=http%3A//image-net.org/challenges/LSVRC/2014/index\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ImageNet Challenge<i class=\"icon-external\"></i></a>竞赛。</blockquote><p><b>课程内容</b>：官方课程安排及资源获取请点击<a href=\"http://link.zhihu.com/?target=http%3A//vision.stanford.edu/teaching/cs231n/syllabus.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">这里<i class=\"icon-external\"></i></a>，课程视频请在Youtube上查看<a href=\"http://link.zhihu.com/?target=https%3A//www.youtube.com/channel/UCPk8m_r6fkUSYmvgCBwq-sw\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Andrej Karpathy<i class=\"icon-external\"></i></a>创建的<a href=\"http://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">播放列表<i class=\"icon-external\"></i></a>，也可私信我们获取云盘视频资源。通过查看官方课程表，我们可以看到：CS231n课程资源主要由<b>授课视频与PPT</b>，<b>授课知识详解笔记</b>和<b>课程作业</b>三部分组成。其中：</p><ul><li><b>授课视频15课</b>。每节课时约1小时左右，每节课一份PPT。<br></li><li><b>授课知识详解笔记共9份</b>。光看课程视频是不够的，深入理解课程笔记才能比较扎实地学习到知识。</li><li><b>课程作业3次</b>。其中每次作业中又包含多个小作业，完成作业能确保对于课程关键知识的深入理解和实现。</li><li><b>课程项目1个</b>。这个更多是面向斯坦福的学生，组队实现课程项目。</li><li><b>拓展阅读若干</b>。课程推荐的拓展阅读大多是领域内的经典著作节选或论文，推荐想要深入学习的同学阅读。</li></ul><p><b>课程评价</b>：我们觉得赞！很多人都觉得赞！当然也有人觉得不好。具体如何，大家搜搜CS231n在网络，在知乎上的评价不就好了嘛！<b>个人认为</b>：入门深度学习的<b>一门良心课</b>。<b>适合绝大多数</b>想要学习深度学习知识的人。</p><p><b>课程不足</b>：课程后期从RCNN开始就没有课程笔记。</p><br><h2>课程学习方法</h2><p>三句话总结：</p><ul><li><b>看授课视频形成概念，发现个人感兴趣方向。</b></li><li><b>读课程笔记理解细节，夯实工程实现的基础。<br></b></li><li><b>码课程作业实现算法，积累实验技巧与经验。</b></li></ul><p>引用一下学习金字塔的图，意思大家都懂的：</p><noscript><img src=\"https://pic4.zhimg.com/77465c8318e6c4d40df274b92602d83f_b.png\" data-rawwidth=\"519\" data-rawheight=\"423\" class=\"origin_image zh-lightbox-thumb\" width=\"519\" data-original=\"https://pic4.zhimg.com/77465c8318e6c4d40df274b92602d83f_r.png\"></noscript><img src=\"//zhstatic.zhihu.com/assets/zhihu/ztext/whitedot.jpg\" data-rawwidth=\"519\" data-rawheight=\"423\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"519\" data-original=\"https://pic4.zhimg.com/77465c8318e6c4d40df274b92602d83f_r.png\" data-actualsrc=\"https://pic4.zhimg.com/77465c8318e6c4d40df274b92602d83f_b.png\"><h2>我们的工作</h2><ul><li><b>完成了CS231n全部9篇课程知识详解笔记的翻译</b>：<br></li></ul><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/python-numpy-tutorial\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[python/numpy tutorial]<i class=\"icon-external\"></i></a>。</p><p>翻译：<a href=\"https://zhuanlan.zhihu.com/p/20878530?refer=intelligentunit\" class=\"internal\">Python Numpy教程</a>。</p><blockquote><p>我们将使用Python编程语言来完成本课程的所有作业。Python是一门伟大的通用编程语言，在一些常用库（numpy, scipy, matplotlib）的帮助下，它又会变成一个强大的科学计算环境。我们期望你们中大多数人对于Python语言和Numpy库比较熟悉，而对于没有Python经验的同学，这篇教程可以帮助你们快速了解Python编程环境和如何使用Python作为科学计算工具。</p></blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/classification\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[image classification notes]<i class=\"icon-external\"></i></a>。</p><p>翻译：<a href=\"https://zhuanlan.zhihu.com/p/20894041?refer=intelligentunit\" class=\"internal\">图像分类笔记（上）</a><a href=\"https://zhuanlan.zhihu.com/p/20900216?refer=intelligentunit\" class=\"internal\">（下）</a>。</p><blockquote>该笔记是一篇介绍性教程，面向非计算机视觉领域的同学。教程将向同学们介绍图像分类问题和数据驱动方法，内容列表：<br><ul><li>图像分类、数据驱动方法和流程<br></li><li>Nearest Neighbor分类器</li><ul><li>k-Nearest Neighbor <i>译者注：上篇翻译截止处</i><br></li></ul><li>验证集、交叉验证集和超参数调参<br></li><li>Nearest Neighbor的优劣<br></li><li>小结<br></li><li>小结：应用kNN实践<br></li><li>拓展阅读</li></ul></blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/linear-classify\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[linear classification notes]<i class=\"icon-external\"></i></a>。<br></p><p>翻译：线性分类笔记<a href=\"https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit\" class=\"internal\">（上）</a><a href=\"https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit\" class=\"internal\">（中）</a><a href=\"https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit\" class=\"internal\">（下）</a>。</p><blockquote>我们将要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：一个是<b>评分函数（score function）</b>，它是原始图像数据到类别分值的映射。另一个是<b>损失函数（loss function）</b>，它是用来量化预测分类标签的得分与真实标签之间一致性的。该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。内容列表：<br><ul><li>线性分类器简介</li><li>线性评分函数</li><li>阐明线性分类器 <i>译者注：上篇翻译截止处</i></li><li>损失函数</li><ul><li>多类SVM</li><li>Softmax分类器</li><li>SVM和Softmax的比较</li></ul><li>基于Web的可交互线性分类器原型</li><li>小结</li></ul></blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/optimization-1\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[optimization notes]<i class=\"icon-external\"></i></a>。<br></p><p>翻译：最优化笔记<a href=\"https://zhuanlan.zhihu.com/p/21360434?refer=intelligentunit\" class=\"internal\">（上）</a><a href=\"https://zhuanlan.zhihu.com/p/21387326?refer=intelligentunit\" class=\"internal\">（下）</a>。</p><blockquote>该笔记介绍了图像分类任务的第三个关键部分：最优化。内容列表如下：<br><ul><li>简介<br></li><li>损失函数可视化</li><li>最优化</li><ul><li>策略#1：随机搜索</li><li>策略#2：随机局部搜索</li><li>策略#3：跟随梯度 <i>译者注：上篇截止处</i></li></ul><li>梯度计算</li><ul><li>使用有限差值进行数值计算</li><li>微分计算梯度</li></ul><li>梯度下降</li><li>小结</li></ul></blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/optimization-2\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[backprop notes]<i class=\"icon-external\"></i></a>。</p><br><p>翻译：<a href=\"https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit\" class=\"internal\">反向传播笔记</a>。</p><blockquote>该笔记本将帮助读者<b>对反向传播形成直观而专业的理解</b>。反向传播是利用链式法则递归计算表达式的梯度的方法。理解反向传播过程及其精妙之处，对于理解、实现、设计和调试神经网络非常关键。内容里列表如下：<br><ul><li>简介</li><li>简单表达式和理解梯度</li><li>复合表达式，链式法则，反向传播</li><li>直观理解反向传播</li><li>模块：Sigmoid例子</li><li>反向传播实践：分段计算</li><li>回传流中的模式</li><li>用户向量化操作的梯度</li><li>小结</li></ul></blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/neural-networks-1/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Neural Nets notes 1<i class=\"icon-external\"></i></a>。</p><p>翻译：神经网络笔记1<a href=\"https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit\" class=\"internal\">（上）</a><a href=\"https://zhuanlan.zhihu.com/p/21513367?refer=intelligentunit\" class=\"internal\">（下）</a>。</p><blockquote>该笔记介绍了神经网络的建模与结构，内容列表如下：<br><ul><li>不用大脑做类比的快速简介</li><li>单个神经元建模<ul><li>生物动机和连接</li><li>作为线性分类器的单个神经元</li><li>常用的激活函数 </li></ul></li><li>神经网络结构<ul><li>层组织</li><li>前向传播计算例子</li><li>表达能力</li><li>设置层的数量和尺寸</li></ul></li><li>小节</li><li>参考文献</li></ul></blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/neural-networks-2/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Neural Nets notes 2<i class=\"icon-external\"></i></a>。</p><p>翻译：<a href=\"https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit\" class=\"internal\">神经网络笔记2</a>。</p><blockquote>该笔记介绍了数据的预处理，正则化和损失函数，内容列表如下：<br><ul><li>设置数据和模型<ul><li>数据预处理</li><li>权重初始化</li><li>批量归一化（Batch Normalization）</li><li>正则化（L2/L1/Maxnorm/Dropout）</li></ul></li><li>损失函数</li><li>小结</li></ul></blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/neural-networks-3/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Neural Nets notes 3<i class=\"icon-external\"></i></a>。</p><p>翻译：神经网络笔记3<a href=\"https://zhuanlan.zhihu.com/p/21741716?refer=intelligentunit\" class=\"internal\">（上）</a><a href=\"https://zhuanlan.zhihu.com/p/21798784?refer=intelligentunit\" class=\"internal\">（下）</a>。</p><blockquote><p>该笔记讲解了神经网络的动态部分，即神经网络学习参数和搜索最优超参数的过程。内容列表如下：<br></p><li>梯度检查</li><li>合理性（Sanity）检查</li><li>检查学习过程<ul><li>损失函数</li><li>训练集与验证集准确率</li><li>权重：更新比例</li><li>每层的激活数据与梯度分布</li><li>可视化 <i>译者注：上篇翻译截止处</i></li></ul></li><li>参数更新<ul><li>一阶（随机梯度下降）方法，动量方法，Nesterov动量方法</li><li>学习率退火</li><li>二阶方法</li><li>逐参数适应学习率方法（Adagrad，RMSProp）</li></ul></li><li>超参数调优</li><li>评价<ul><li>模型集成</li></ul></li><li>总结</li><li>拓展引用</li></blockquote><br><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/convolutional-networks/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ConvNet notes<i class=\"icon-external\"></i></a>。</p><p>翻译：<a href=\"https://zhuanlan.zhihu.com/p/22038289?refer=intelligentunit\" class=\"internal\">卷积神经网络笔记</a>。</p><blockquote><p>内容列表：</p><ul><li><b>结构概述</b></li><li><b>用来构建卷积神经网络的各种层</b><br><ul><li>卷积层</li><li>汇聚层</li><li>归一化层</li><li>全连接层</li><li>将全连接层转化成卷积层</li></ul></li><li><b>卷积神经网络的结构</b><ul><li>层的排列规律</li><li>层的尺寸设置规律</li><li>案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）</li><li>计算上的考量</li></ul></li><li><b>拓展资源</b></li></ul></blockquote><br><ul><li><b>完成了3个课程作业页面的翻译</b>：<br></li></ul><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/assignments2016/assignment1/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[Assignment #1]<i class=\"icon-external\"></i></a>。<br></p><p>翻译：<a href=\"https://zhuanlan.zhihu.com/p/21441838?refer=intelligentunit\" class=\"internal\">CS231n课程作业#1简介</a>。</p><blockquote>作业内容：实现k-NN，SVM分类器，Softmax分类器和两层神经网络，实践一个简单的图像分类流程。</blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/assignments2016/assignment2/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[Assignment #2]<i class=\"icon-external\"></i></a>。<br></p><p>翻译：<a href=\"https://zhuanlan.zhihu.com/p/21941485?refer=intelligentunit\" class=\"internal\">CS231n课程作业#2简介</a>。</p><blockquote>作业内容：练习编写反向传播代码，训练神经网络和卷积神经网络。</blockquote><br><p>原文：<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/assignments2016/assignment3/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">[Assignment #3]<i class=\"icon-external\"></i></a>。<br></p><p>翻译：<a href=\"https://zhuanlan.zhihu.com/p/21946525?refer=intelligentunit\" class=\"internal\">CS231n课程作业#3简介</a>。</p><blockquote>作业内容：实现循环网络，并将其应用于在微软的COCO数据库上进行图像标注。实现DeepDream等有趣应用。</blockquote><br><ul><li><b>帮助知友<a href=\"http://www.zhihu.com/people/313544833f1060900fcb4f6a75c9f6b6\" data-hash=\"313544833f1060900fcb4f6a75c9f6b6\" class=\"member_mention\" data-title=\"@智靖远\" data-editable=\"true\" data-hovercard=\"p$b$313544833f1060900fcb4f6a75c9f6b6\">@智靖远</a>发起了在Youtube上合力翻译课程字幕的倡议</b>：</li></ul><p>原文：<a href=\"https://zhuanlan.zhihu.com/p/21354230?refer=intelligentunit\" class=\"internal\">知友智靖远关于CS231n课程字幕翻译的倡议</a>。当时，<a href=\"http://www.zhihu.com/people/313544833f1060900fcb4f6a75c9f6b6\" data-hash=\"313544833f1060900fcb4f6a75c9f6b6\" class=\"member_mention\" data-title=\"@智靖远\" data-editable=\"true\" data-hovercard=\"p$b$313544833f1060900fcb4f6a75c9f6b6\">@智靖远</a>已经贡献了他对第一课字幕的翻译，目前这个翻译项目仍在进行中，欢迎各位知友积极参与。具体操作方式在倡议原文中有，请大家点击查看。</p><p>有很多知友私信我们，询问为何不做字幕。现在统一答复：<b>请大家积极参加<a href=\"http://www.zhihu.com/people/313544833f1060900fcb4f6a75c9f6b6\" data-hash=\"313544833f1060900fcb4f6a75c9f6b6\" class=\"member_mention\" data-title=\"@智靖远\" data-editable=\"true\" data-hovercard=\"p$b$313544833f1060900fcb4f6a75c9f6b6\">@智靖远</a>的字幕翻译项目。</b>他先进行的字幕贡献与翻译，我们<b>不能夺人之美</b>。<b>后续，我们也会向该翻译项目进行贡献</b>。</p><h2>翻译团队</h2><p>CS231n课程笔记的翻译，始于<a href=\"http://www.zhihu.com/people/928affb05b0b70a2c12e109d63b6bae5\" data-hash=\"928affb05b0b70a2c12e109d63b6bae5\" class=\"member_mention\" data-editable=\"true\" data-title=\"@杜客\" data-hovercard=\"p$b$928affb05b0b70a2c12e109d63b6bae5\">@杜客</a>在一次回答问题“<a href=\"https://www.zhihu.com/question/41907061\" class=\"internal\">应该选择TensorFlow还是Theano？</a>”中的机缘巧合，在<a href=\"https://zhuanlan.zhihu.com/p/20870307?refer=intelligentunit\" class=\"internal\">取得了授权</a>后申请了知乎专栏<a href=\"https://zhuanlan.zhihu.com/intelligentunit\" class=\"internal\">智能单元 - 知乎专栏</a>独自翻译。随着翻译的进行，更多的知友参与进来。他们是<a href=\"http://www.zhihu.com/people/584f06e4ed2edc6007e4793179e7cdc1\" data-hash=\"584f06e4ed2edc6007e4793179e7cdc1\" class=\"member_mention\" data-title=\"@ShiqingFan\" data-editable=\"true\" data-hovercard=\"p$b$584f06e4ed2edc6007e4793179e7cdc1\">@ShiqingFan</a>，@<a href=\"https://www.zhihu.com/people/hmonkey\" class=\"internal\">猴子</a>，<a href=\"http://www.zhihu.com/people/e7fcc05b0cf8a90a3e676d0206f888c9\" data-hash=\"e7fcc05b0cf8a90a3e676d0206f888c9\" class=\"member_mention\" data-editable=\"true\" data-title=\"@堃堃\" data-hovercard=\"p$b$e7fcc05b0cf8a90a3e676d0206f888c9\">@堃堃</a>和<a href=\"http://www.zhihu.com/people/f11e78650e8185db2b013af42fd9a481\" data-hash=\"f11e78650e8185db2b013af42fd9a481\" class=\"member_mention\" data-editable=\"true\" data-title=\"@李艺颖\" data-hovercard=\"p$b$f11e78650e8185db2b013af42fd9a481\">@李艺颖</a>。</p><p><b>大家因为认同这件事而聚集在一起</b>，牺牲了很多个人的时间来进行翻译，校对和润色。而翻译的质量，我们不愿意自我表扬，还是<b>请各位知友自行阅读评价</b>吧。现在笔记翻译告一段落，下面是<b>团队成员的简短感言</b>：</p><p><a href=\"http://www.zhihu.com/people/584f06e4ed2edc6007e4793179e7cdc1\" data-hash=\"584f06e4ed2edc6007e4793179e7cdc1\" class=\"member_mention\" data-editable=\"true\" data-title=\"@ShiqingFan\" data-hovercard=\"p$b$584f06e4ed2edc6007e4793179e7cdc1\">@ShiqingFan</a> ：一个偶然的机会让自己加入到这个翻译小队伍里来。CS231n给予了我知识的源泉和思考的灵感，前期的翻译工作也督促自己快速了学习了这门课程。虽然科研方向是大数据与并行计算，不过因为同时对深度学习比较感兴趣，于是乎现在的工作与两者都紧密相连。Merci!<br></p><p>@<a href=\"https://www.zhihu.com/people/hmonkey\" class=\"internal\">猴子</a>：在CS231n翻译小组工作的两个多月的时间非常难忘。我向杜客申请加入翻译小组的时候，才刚接触这门课不久，翻译和校对的工作让我对这门课的内容有了更深刻的理解。作为一个机器学习的初学者，我非常荣幸能和翻译小组一起工作并做一点贡献。希望以后能继续和翻译小组一起工作和学习。</p><p><a href=\"http://www.zhihu.com/people/e7fcc05b0cf8a90a3e676d0206f888c9\" data-hash=\"e7fcc05b0cf8a90a3e676d0206f888c9\" class=\"member_mention\" data-editable=\"true\" data-title=\"@堃堃\" data-hovercard=\"p$b$e7fcc05b0cf8a90a3e676d0206f888c9\">@堃堃</a> ：感谢组内各位成员的辛勤付出，很幸运能够参与这份十分有意义的工作，希望自己的微小工作能够帮助到大家，谢谢！<br></p><p><a href=\"http://www.zhihu.com/people/f11e78650e8185db2b013af42fd9a481\" data-hash=\"f11e78650e8185db2b013af42fd9a481\" class=\"member_mention\" data-editable=\"true\" data-title=\"@李艺颖\" data-hovercard=\"p$b$f11e78650e8185db2b013af42fd9a481\">@李艺颖</a> ：当你真正沉下心来要做一件事情的时候才是学习和提高最好的状态；当你有热情做事时，并不会觉得是在牺牲时间，因为那是有意义并能带给你成就感和充实感的；不需要太过刻意地在乎大牛的巨大光芒，你只需像傻瓜一样坚持下去就好了，也许回头一看，你已前进了很多。就像老杜说的，我们就是每一步慢慢走，怎么就“零星”地把这件事给搞完了呢？<br></p><p><a href=\"http://www.zhihu.com/people/928affb05b0b70a2c12e109d63b6bae5\" data-hash=\"928affb05b0b70a2c12e109d63b6bae5\" class=\"member_mention\" data-editable=\"true\" data-title=\"@杜客\" data-hovercard=\"p$b$928affb05b0b70a2c12e109d63b6bae5\">@杜客</a> ：做了一点微小的工作，哈哈。<br></p><h2>未来工作</h2><p>目前通过大家的反馈，之后会有新的创作方向，会更多与大家互动，敬请期待吧！</p><h2>感谢</h2><p>感谢<b>所有给我们的翻译提出过批评指正的知友</b>，每篇文章末尾处的译者反馈部分我们都列出了大家的具体指正与贡献；</p><p>感谢<b>所有给我们的翻译点赞的知友</b>，你们的赞是我们的精神粮食；</p><p>感谢<b>给文章赞赏小钱钱的知友</b>，谢谢老板们：）</p><h2>最后</h2><p><b>恳请大家点赞和分享到其他社交网络上</b>，让更多<b>想要入门与系统学习深度学习</b>的小伙伴能够看到这篇总集。同时，也欢迎大家在来专栏分享你的知识，发现志同道合的朋友！</p><p><b>这个世界需要更多的英雄！</b></p>","updated":"2016-08-25T07:47:00.000Z","canComment":true,"commentPermission":"anyone","commentCount":157,"collapsedCount":0,"likeCount":1071,"state":"published","isLiked":true,"slug":"21930884","lastestTipjarors":[{"isFollowed":false,"name":"崔永明","headline":"","avatarUrl":"https://pic1.zhimg.com/da8e974dc_s.jpg","isFollowing":false,"type":"people","slug":"cui-yong-ming-88","bio":"码农","hash":"635e2dc5122d9f8cf888d1c4b9e18f3b","uid":29965517062144,"isOrg":false,"description":"","profileUrl":"https://www.zhihu.com/people/cui-yong-ming-88","avatar":{"id":"da8e974dc","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"isFollowed":false,"name":"KyrieHe","headline":"keep simple","avatarUrl":"https://pic3.zhimg.com/v2-4acf843c9cc872a09aa3435529506d3a_s.jpg","isFollowing":false,"type":"people","slug":"kyriehe","bio":"一枚普通的CS程序员","hash":"578b37825de8f9796e2bcbbcb6eeaa90","uid":737554037561368600,"isOrg":false,"description":"keep simple","profileUrl":"https://www.zhihu.com/people/kyriehe","avatar":{"id":"v2-4acf843c9cc872a09aa3435529506d3a","template":"https://pic3.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"isFollowed":false,"name":"彭一洋","headline":"个人网站yiyang186.github.io  \nGithub: github.com/yiyang186 \n博客blog.csdn.net/q1w2e3r4470?viewmode=contents  ","avatarUrl":"https://pic1.zhimg.com/v2-71f34462a46a2320defee24677263628_s.jpg","isFollowing":false,"type":"people","slug":"peng-yiyang-88","bio":"ML小学生/DM小学生/CS小学生/优化概率统计代数小学生","hash":"6a2eee989c612346a4ef80dc21562d92","uid":661162956839194600,"isOrg":false,"description":"个人网站yiyang186.github.io  \nGithub: github.com/yiyang186 \n博客blog.csdn.net/q1w2e3r4470?viewmode=contents  ","profileUrl":"https://www.zhihu.com/people/peng-yiyang-88","avatar":{"id":"v2-71f34462a46a2320defee24677263628","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"isFollowed":false,"name":"玫荷居士第二","headline":"主不在乎","avatarUrl":"https://pic4.zhimg.com/efa0ea58ee0775b73d6527f8740f12f3_s.jpg","isFollowing":false,"type":"people","slug":"lan-ni-si-te-88","bio":"我是一个可爱的男孩","hash":"fc92717e1907debbf842554441b9e85f","uid":654066320816214000,"isOrg":false,"description":"主不在乎","profileUrl":"https://www.zhihu.com/people/lan-ni-si-te-88","avatar":{"id":"efa0ea58ee0775b73d6527f8740f12f3","template":"https://pic4.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"isFollowed":false,"name":"甲级演员","headline":"","avatarUrl":"https://pic1.zhimg.com/da8e974dc_s.jpg","isFollowing":false,"type":"people","slug":"jia-ji-yan-yuan-79","bio":"自然资源的研究生","hash":"a53a23d55a673822c3f5f973083ca511","uid":850035327807684600,"isOrg":false,"description":"","profileUrl":"https://www.zhihu.com/people/jia-ji-yan-yuan-79","avatar":{"id":"da8e974dc","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"isFollowed":false,"name":"马啊嚏","headline":"","avatarUrl":"https://pic2.zhimg.com/646d46adc7b164548949947e4091ad81_s.jpg","isFollowing":false,"type":"people","slug":"ma-a-ti","bio":null,"hash":"e90cb05ace81f8101dd38542870c0038","uid":618391823870201900,"isOrg":false,"description":"","profileUrl":"https://www.zhihu.com/people/ma-a-ti","avatar":{"id":"646d46adc7b164548949947e4091ad81","template":"https://pic2.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"isFollowed":false,"name":"杨明祺","headline":"","avatarUrl":"https://pic1.zhimg.com/da8e974dc_s.jpg","isFollowing":false,"type":"people","slug":"yang-ming-qi-98","bio":null,"hash":"529d6e44f132eff4ae7d10300153e2f7","uid":38712910020608,"isOrg":false,"description":"","profileUrl":"https://www.zhihu.com/people/yang-ming-qi-98","avatar":{"id":"da8e974dc","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"isFollowed":false,"name":"ryenC","headline":"","avatarUrl":"https://pic3.zhimg.com/aafbfedee_s.jpg","isFollowing":false,"type":"people","slug":"rryen","bio":null,"hash":"5e15e9f871f2d8646283e0f530032f8d","uid":28157243555840,"isOrg":false,"description":"","profileUrl":"https://www.zhihu.com/people/rryen","avatar":{"id":"aafbfedee","template":"https://pic3.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false}],"isTitleImageFullScreen":false,"rating":"like","titleImage":"https://pic3.zhimg.com/0dee7274beed25bd4abbcd76cb7d9576_r.jpg","links":{"comments":"/api/posts/21930884/comments"},"reviewers":["li-yi-ying-73","kun-kun-97-81","sqfan","hmonkey"],"topics":[{"url":"https://www.zhihu.com/topic/19559450","id":"19559450","name":"机器学习"},{"url":"https://www.zhihu.com/topic/19630200","id":"19630200","name":"资源共享"},{"url":"https://www.zhihu.com/topic/19566266","id":"19566266","name":"学习方法"}],"adminClosedComment":false,"titleImageSize":{"width":990,"height":300},"href":"/api/posts/21930884","excerptTitle":"","column":{"slug":"intelligentunit","name":"智能单元"},"tipjarState":"activated","tipjarTagLine":"谢谢老板们","sourceUrl":"","pageCommentsCount":157,"tipjarorCount":50,"annotationAction":[],"snapshotUrl":"","publishedTime":"2016-08-25T15:47:00+08:00","url":"/p/21930884","lastestLikers":[{"bio":"程序员","isFollowing":false,"hash":"b8417456e21dff4c1bbc40e26f36bb5a","uid":793490972775432200,"isOrg":false,"slug":"mjqzh","isFollowed":false,"description":"","name":"mjqzh","profileUrl":"https://www.zhihu.com/people/mjqzh","avatar":{"id":"da8e974dc","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"bio":"漂泊在东瀛","isFollowing":false,"hash":"37634e08b6d7b207e072bef1653121b3","uid":27691092803584,"isOrg":false,"slug":"lhsfcboy","isFollowed":false,"description":"","name":"深蓝","profileUrl":"https://www.zhihu.com/people/lhsfcboy","avatar":{"id":"f5471202a","template":"https://pic3.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"bio":"音乐|数据科学|物理|化学","isFollowing":false,"hash":"6ff9e860659f2c68e6181b680c248789","uid":31213477691392,"isOrg":false,"slug":"peng-bo-90","isFollowed":false,"description":"合唱／吉他／音乐理论","name":"彭博","profileUrl":"https://www.zhihu.com/people/peng-bo-90","avatar":{"id":"8cf5dd2b41d300cbbb3a64f33b314407","template":"https://pic4.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"bio":"苦逼的学生","isFollowing":false,"hash":"6f841babd75d4cb948f0cad428848bfd","uid":659892325975724000,"isOrg":false,"slug":"uanheng","isFollowed":false,"description":"","name":"此间过客","profileUrl":"https://www.zhihu.com/people/uanheng","avatar":{"id":"27330dd6c8915c8eecfcd55239962568","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},{"bio":null,"isFollowing":false,"hash":"89238711b60b01eca7d7d3f7ca500f66","uid":28463549382656,"isOrg":false,"slug":"mo-mou-yong","isFollowed":false,"description":"","name":"万谋勇","profileUrl":"https://www.zhihu.com/people/mo-mou-yong","avatar":{"id":"50e1352f1","template":"https://pic2.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false}],"summary":"<img src=\"http://pic4.zhimg.com/77465c8318e6c4d40df274b92602d83f_200x112.png\" data-rawwidth=\"519\" data-rawheight=\"423\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"http://pic4.zhimg.com/77465c8318e6c4d40df274b92602d83f_r.png\">哈哈哈！我们也是不谦虚，几个“业余水平”的网友，怎么就“零星”地把这件事给搞完了呢！<b>总之就是非常开心</b>，废话不多说，进入正题吧！CS231n简介CS231n的全称是<a href=\"http://vision.stanford.edu/teaching/cs231n/index.html\" data-editable=\"true\" data-title=\"CS231n: Convolutional Neural Networks for Visual Recognition\" class=\"\">CS231n: Convolutional Neural Networks for Visual Recognition</a>，即<b>面向视觉识别的卷积神经网络</b>…","reviewingCommentsCount":0,"meta":{"previous":{"isTitleImageFullScreen":false,"rating":"none","titleImage":"https://pic3.zhimg.com/5b83bc8331994f47fedb1459d1424872_r.png","links":{"comments":"/api/posts/22038289/comments"},"topics":[{"url":"https://www.zhihu.com/topic/19551275","id":"19551275","name":"人工智能"},{"url":"https://www.zhihu.com/topic/19559450","id":"19559450","name":"机器学习"},{"url":"https://www.zhihu.com/topic/20043586","id":"20043586","name":"卷积神经网络（CNN）"}],"adminClosedComment":false,"href":"/api/posts/22038289","excerptTitle":"","author":{"bio":"学生","isFollowing":false,"hash":"77a6055b8d73148aee3464cf7a3b8d09","uid":557306122193793000,"isOrg":false,"slug":"hmonkey","isFollowed":false,"description":"机器学习\\深度学习方向初学者","name":"猴子","profileUrl":"https://www.zhihu.com/people/hmonkey","avatar":{"id":"f0c45ebc982d64ea0c4822517e7285ac","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},"content":"<p><b>译者注</b>：本文翻译自斯坦福CS231n课程笔记<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/convolutional-networks/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ConvNet notes<i class=\"icon-external\"></i></a>，由课程教师<a href=\"http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Andrej Karpathy<i class=\"icon-external\"></i></a>授权进行翻译。本篇教程由<a href=\"https://www.zhihu.com/people/du-ke\" class=\"internal\">杜客</a>和<a href=\"https://www.zhihu.com/people/hmonkey\" class=\"internal\">猴子</a>翻译完成，<a href=\"https://www.zhihu.com/people/kun-kun-97-81\" class=\"internal\">堃堃</a>和<a href=\"https://www.zhihu.com/people/li-yi-ying-73\" class=\"internal\">李艺颖</a>进行校对修改。</p><br><br><h2>原文如下</h2><p>内容列表：</p><ul><li><b>结构概述</b></li><li><b>用来构建卷积神经网络的各种层</b><br><ul><li>卷积层</li><li>汇聚层</li><li>归一化层</li><li>全连接层</li><li>将全连接层转化成卷积层</li></ul></li><li><b>卷积神经网络的结构</b><ul><li>层的排列规律</li><li>层的尺寸设置规律</li><li>案例学习（LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet）</li><li>计算上的考量</li></ul></li><li><b>拓展资源</b></li></ul><br><br><h2><b>卷积神经网络（CNNs / ConvNets）</b></h2><p>卷积神经网络和上一章讲的常规神经网络非常相似：它们都是由神经元组成，神经元中有具有学习能力的权重和偏差。每个神经元都得到一些输入数据，进行内积运算后再进行激活函数运算。整个网络依旧是一个可导的评分函数：该函数的输入是原始的图像像素，输出是不同类别的评分。在最后一层（往往是全连接层），网络依旧有一个损失函数（比如SVM或Softmax），并且在神经网络中我们实现的各种技巧和要点依旧适用于卷积神经网络。</p><p>那么有哪些地方变化了呢？卷积神经网络的结构基于一个假设，即输入数据是图像，基于该假设，我们就向结构中添加了一些特有的性质。这些特有属性使得前向传播函数实现起来更高效，并且大幅度降低了网络中参数的数量。</p><br><br><h2><b>结构概述</b></h2><p><i>回顾：常规神经网络</i>。在上一章中，神经网络的输入是一个向量，然后在一系列的<i>隐层</i>中对它做变换。每个隐层都是由若干的神经元组成，每个神经元都与前一层中的所有神经元连接。但是在一个隐层中，神经元相互独立不进行任何连接。最后的全连接层被称为“输出层”，在分类问题中，它输出的值被看做是不同类别的评分值。</p><p><i>常规神经网络对于大尺寸图像效果不尽人意</i>。在CIFAR-10中，图像的尺寸是32x32x3（宽高均为32像素，3个颜色通道），因此，对应的的常规神经网络的第一个隐层中，每一个单独的全连接神经元就有32x32x3=3072个权重。这个数量看起来还可以接受，但是很显然这个全连接的结构不适用于更大尺寸的图像。举例说来，一个尺寸为200x200x3的图像，会让神经元包含200x200x3=120,000个权重值。而网络中肯定不止一个神经元，那么参数的量就会快速增加！显而易见，这种全连接方式效率低下，大量的参数也很快会导致网络过拟合。</p><p><i>神经元的三维排列</i>。卷积神经网络针对输入全部是图像的情况，将结构调整得更加合理，获得了不小的优势。与常规神经网络不同，卷积神经网络的各层中的神经元是3维排列的：<b>宽度</b>、<b>高度</b>和<b>深度</b>（这里的<b>深度</b>指的是激活数据体的第三个维度，而不是整个网络的深度，整个网络的深度指的是网络的层数）。举个例子，CIFAR-10中的图像是作为卷积神经网络的输入，该数据体的维度是32x32x3（宽度，高度和深度）。我们将看到，层中的神经元将只与前一层中的一小块区域连接，而不是采取全连接方式。对于用来分类CIFAR-10中的图像的卷积网络，其最后的输出层的维度是1x1x10，因为在卷积神经网络结构的最后部分将会把全尺寸的图像压缩为包含分类评分的一个向量，向量是在深度方向排列的。下面是例子：</p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><img src=\"http://pic2.zhimg.com/2ef08bb4cf60805d726b2d6db39dd985_b.jpg\" data-rawwidth=\"1637\" data-rawheight=\"379\" class=\"origin_image zh-lightbox-thumb\" width=\"1637\" data-original=\"http://pic2.zhimg.com/2ef08bb4cf60805d726b2d6db39dd985_r.jpg\">左边是一个3层的神经网络。右边是一个卷积神经网络，图例中网络将它的神经元都排列成3个维度（宽、高和深度）。卷积神经网络的每一层都将3D的输入数据变化为神经元3D的激活数据并输出。在这个例子中，红色的输入层装的是图像，所以它的宽度和高度就是图像的宽度和高度，它的深度是3（代表了红、绿、蓝3种颜色通道）。<img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><blockquote><p>卷积神经网络是由层组成的。每一层都有一个简单的API：用一些含或者不含参数的可导的函数，将输入的3D数据变换为3D的输出数据。</p></blockquote><br><h3><b>用来构建卷积网络的各种层</b></h3><p>一个简单的卷积神经网络是由各种层按照顺序排列组成，网络中的每个层使用一个可以微分的函数将激活数据从一个层传递到另一个层。卷积神经网络主要由三种类型的层构成：<b>卷积层</b>，<b>汇聚（Pooling）层</b>和<b>全连接层</b>（全连接层和常规神经网络中的一样）。通过将这些层叠加起来，就可以构建一个完整的卷积神经网络。</p><p><i>网络结构例子：</i>这仅仅是个概述，下面会更详解的介绍细节。一个用于CIFAR-10图像数据分类的卷积神经网络的结构可以是[输入层-卷积层-ReLU层-汇聚层-全连接层]。细节如下：</p><ul><li>输入[32x32x3]存有图像的原始像素值，本例中图像宽高均为32，有3个颜色通道。<br></li><li>卷积层中，神经元与输入层中的一个局部区域相连，每个神经元都计算自己与输入层相连的小区域与自己权重的内积。卷积层会计算所有神经元的输出。如果我们使用12个滤波器（也叫作核），得到的输出数据体的维度就是[32x32x12]。<br></li><li>ReLU层将会逐个元素地进行激活函数操作，比如使用以0为阈值的<img src=\"http://www.zhihu.com/equation?tex=max%280%2Cx%29\" alt=\"max(0,x)\" eeimg=\"1\">作为激活函数。该层对数据尺寸没有改变，还是[32x32x12]。<br></li><li>汇聚层在在空间维度（宽度和高度）上进行降采样（downsampling）操作，数据尺寸变为[16x16x12]。<br></li><li>全连接层将会计算分类评分，数据尺寸变为[1x1x10]，其中10个数字对应的就是CIFAR-10中10个类别的分类评分值。正如其名，全连接层与常规神经网络一样，其中每个神经元都与前一层中所有神经元相连接。</li></ul><p>由此看来，卷积神经网络一层一层地将图像从原始像素值变换成最终的分类评分值。其中有的层含有参数，有的没有。具体说来，卷积层和全连接层（CONV/FC）对输入执行变换操作的时候，不仅会用到激活函数，还会用到很多参数（神经元的突触权值和偏差）。而ReLU层和汇聚层则是进行一个固定不变的函数操作。卷积层和全连接层中的参数会随着梯度下降被训练，这样卷积神经网络计算出的分类评分就能和训练集中的每个图像的标签吻合了。</p><p><b>小结</b>：</p><ul><li>简单案例中卷积神经网络的结构，就是一系列的层将输入数据变换为输出数据（比如分类评分）。<br></li><li>卷积神经网络结构中有几种不同类型的层（目前最流行的有卷积层、全连接层、ReLU层和汇聚层）。<br></li><li>每个层的输入是3D数据，然后使用一个可导的函数将其变换为3D的输出数据。<br></li><li>有的层有参数，有的没有（卷积层和全连接层有，ReLU层和汇聚层没有）。</li><li>有的层有额外的超参数，有的没有（卷积层、全连接层和汇聚层有，ReLU层没有）。</li></ul><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><img src=\"http://pic3.zhimg.com/d9259be829b1cdb3d98a399ebc56defa_b.jpg\" data-rawwidth=\"1255\" data-rawheight=\"601\" class=\"origin_image zh-lightbox-thumb\" width=\"1255\" data-original=\"http://pic3.zhimg.com/d9259be829b1cdb3d98a399ebc56defa_r.jpg\">一个卷积神经网络的激活输出例子。左边的输入层存有原始图像像素，右边的输出层存有类别分类评分。在处理流程中的每个激活数据体是铺成一列来展示的。因为对3D数据作图比较困难，我们就把每个数据体切成层，然后铺成一列显示。最后一层装的是针对不同类别的分类得分，这里只显示了得分最高的5个评分值和对应的类别。完整的<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.stanford.edu/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">网页演示<i class=\"icon-external\"></i></a>在我们的课程主页。本例中的结构是一个小的VGG网络，VGG网络后面会有讨论。<img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><p>现在讲解不同的层，层的超参数和连接情况的细节。</p><br><h4>卷积层</h4><p>卷积层是构建卷积神经网络的核心层，它产生了网络中大部分的计算量。</p><p><b>概述和直观介绍</b>：首先讨论的是，在没有大脑和生物意义上的神经元之类的比喻下，卷积层到底在计算什么。卷积层的参数是有一些可学习的滤波器集合构成的。每个滤波器在空间上（宽度和高度）都比较小，但是深度和输入数据一致。举例来说，卷积神经网络第一层的一个典型的滤波器的尺寸可以是5x5x3（宽高都是5像素，深度是3是因为图像应为颜色通道，所以有3的深度）。在前向传播的时候，让每个滤波器都在输入数据的宽度和高度上滑动（更精确地说是卷积），然后计算整个滤波器和输入数据任一处的内积。当滤波器沿着输入数据的宽度和高度滑过后，会生成一个2维的激活图（activation map），激活图给出了在每个空间位置处滤波器的反应。直观地来说，网络会让滤波器学习到当它看到某些类型的视觉特征时就激活，具体的视觉特征可能是某些方位上的边界，或者在第一层上某些颜色的斑点，甚至可以是网络更高层上的蜂巢状或者车轮状图案。</p><br><p>在每个卷积层上，我们会有一整个集合的滤波器（比如12个），每个都会生成一个不同的二维激活图。将这些激活映射在深度方向上层叠起来就生成了输出数据。</p><p><b>以大脑做比喻</b>：如果你喜欢用大脑和生物神经元来做比喻，那么输出的3D数据中的每个数据项可以被看做是神经元的一个输出，而该神经元只观察输入数据中的一小部分，并且和空间上左右两边的所有神经元共享参数（因为这些数字都是使用同一个滤波器得到的结果）。现在开始讨论神经元的连接，它们在空间中的排列，以及它们参数共享的模式。<br></p><p><b>局部连接</b>：在处理图像这样的高维度输入时，让每个神经元都与前一层中的所有神经元进行全连接是不现实的。相反，我们让每个神经元只与输入数据的一个局部区域连接。该连接的空间大小叫做神经元的<b>感受野（receptive field）</b>，它的尺寸是一个超参数（其实就是滤波器的空间尺寸）。在深度方向上，这个连接的大小总是和输入量的深度相等。需要再次强调的是，我们对待空间维度（宽和高）与深度维度是不同的：连接在空间（宽高）上是局部的，但是在深度上总是和输入数据的深度一致。</p><p><i>例1</i>：假设输入数据体尺寸为[32x32x3]（比如CIFAR-10的RGB图像），如果感受野（或滤波器尺寸）是5x5，那么卷积层中的每个神经元会有输入数据体中[5x5x3]区域的权重，共5x5x3=75个权重（还要加一个偏差参数）。注意这个连接在深度维度上的大小必须为3，和输入数据体的深度一致。</p><p><i>例2</i>：假设输入数据体的尺寸是[16x16x20]，感受野尺寸是3x3，那么卷积层中每个神经元和输入数据体就有3x3x20=180个连接。再次提示：在空间上连接是局部的（3x3），但是在深度上是和输入数据体一致的（20）。</p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><img src=\"http://pic4.zhimg.com/ba9dcfa847a71cb695c2653230ea9147_b.jpg\" data-rawwidth=\"1031\" data-rawheight=\"334\" class=\"origin_image zh-lightbox-thumb\" width=\"1031\" data-original=\"http://pic4.zhimg.com/ba9dcfa847a71cb695c2653230ea9147_r.jpg\"><br><p><b>左边</b>：红色的是输入数据体（比如CIFAR-10中的图像），蓝色的部分是第一个卷积层中的神经元。卷积层中的每个神经元都只是与输入数据体的一个局部在空间上相连，但是与输入数据体的所有深度维度全部相连（所有颜色通道）。在深度方向上有多个神经元（本例中5个），它们都接受输入数据的同一块区域（<b>感受野</b>相同）。至于深度列的讨论在下文中有。</p><br><p><b>右边</b>：神经网络章节中介绍的神经元保持不变，它们还是计算权重和输入的内积，然后进行激活函数运算，只是它们的连接被限制在一个局部空间。</p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><p><b>空间排列</b>：上文讲解了卷积层中每个神经元与输入数据体之间的连接方式，但是尚未讨论输出数据体中神经元的数量，以及它们的排列方式。3个超参数控制着输出数据体的尺寸：<b>深度（depth），步长（stride）</b>和<b>零填充（zero-padding）</b>。下面是对它们的讨论：</p><ol><li>首先，输出数据体的深度是一个超参数：它和使用的滤波器的数量一致，而每个滤波器在输入数据中寻找一些不同的东西。举例来说，如果第一个卷积层的输入是原始图像，那么在深度维度上的不同神经元将可能被不同方向的边界，或者是颜色斑点激活。我们将这些沿着深度方向排列、感受野相同的神经元集合称为<b>深度列（depth column）</b>，也有人使用纤维（fibre）来称呼它们。</li><li>其次，在滑动滤波器的时候，必须指定步长。当步长为1，滤波器每次移动1个像素。当步长为2（或者不常用的3，或者更多，这些在实际中很少使用），滤波器滑动时每次移动2个像素。这个操作会让输出数据体在空间上变小。</li><li>在下文可以看到，有时候将输入数据体用0在边缘处进行填充是很方便的。这个<b>零填充（zero-padding）</b>的尺寸是一个超参数。零填充有一个良好性质，即可以控制输出数据体的空间尺寸（最常用的是用来保持输入数据体在空间上的尺寸，这样输入和输出的宽高都相等）。<br></li></ol><p>输出数据体在空间上的尺寸可以通过输入数据体尺寸（W），卷积层中神经元的感受野尺寸（F），步长（S）和零填充的数量（P）的函数来计算。（<i><b>译者注</b>：这里假设输入数组的空间形状是正方形，即高度和宽度相等</i>）输出数据体的空间尺寸为(W-F +2P)/S+1。比如输入是7x7，滤波器是3x3，步长为1，填充为0，那么就能得到一个5x5的输出。如果步长为2，输出就是3x3。下面是例子：</p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><img src=\"http://pic3.zhimg.com/90af0bd67ba498239688c81fd61bbc66_b.jpg\" data-rawwidth=\"861\" data-rawheight=\"172\" class=\"origin_image zh-lightbox-thumb\" width=\"861\" data-original=\"http://pic3.zhimg.com/90af0bd67ba498239688c81fd61bbc66_r.jpg\"><p>空间排列的图示。在本例中只有一个空间维度（x轴），神经元的感受野尺寸F=3，输入尺寸W=5，零填充P=1。左边：神经元使用的步长S=1，所以输出尺寸是(5-3+2)/1+1=5。右边：神经元的步长S=2，则输出尺寸是(5-3+2)/2+1=3。注意当步长S=3时是无法使用的，因为它无法整齐地穿过数据体。从等式上来说，因为(5-3+2)=4是不能被3整除的。</p><p>本例中，神经元的权重是[1,0,-1]，显示在图的右上角，偏差值为0。这些权重是被所有黄色的神经元共享的（参数共享的内容看下文相关内容）。</p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><p><i>使用零填充</i>：在上面左边例子中，注意输入维度是5，输出维度也是5。之所以如此，是因为感受野是3并且使用了1的零填充。如果不使用零填充，则输出数据体的空间维度就只有3，因为这就是滤波器整齐滑过并覆盖原始数据需要的数目。一般说来，当步长<img src=\"http://www.zhihu.com/equation?tex=S%3D1\" alt=\"S=1\" eeimg=\"1\">时，零填充的值是<img src=\"http://www.zhihu.com/equation?tex=P%3D%28F-1%29%2F2\" alt=\"P=(F-1)/2\" eeimg=\"1\">，这样就能保证输入和输出数据体有相同的空间尺寸。这样做非常常见，在介绍卷积神经网络的结构的时候我们会详细讨论其原因。<br></p><p><i>步长的限制</i>：注意这些空间排列的超参数之间是相互限制的。举例说来，当输入尺寸<img src=\"http://www.zhihu.com/equation?tex=W%3D10\" alt=\"W=10\" eeimg=\"1\">，不使用零填充则<img src=\"http://www.zhihu.com/equation?tex=P%3D0\" alt=\"P=0\" eeimg=\"1\">，滤波器尺寸<img src=\"http://www.zhihu.com/equation?tex=F%3D3\" alt=\"F=3\" eeimg=\"1\">，这样步长<img src=\"http://www.zhihu.com/equation?tex=S%3D2\" alt=\"S=2\" eeimg=\"1\">就行不通，因为<img src=\"http://www.zhihu.com/equation?tex=%28W-F%2B2P%29%2FS%2B1%3D%2810-3%2B0%29%2F2%2B1%3D4.5\" alt=\"(W-F+2P)/S+1=(10-3+0)/2+1=4.5\" eeimg=\"1\">，结果不是整数，这就是说神经元不能整齐对称地滑过输入数据体。因此，这些超参数的设定就被认为是无效的，一个卷积神经网络库可能会报出一个错误，或者修改零填充值来让设置合理，或者修改输入数据体尺寸来让设置合理，或者其他什么措施。在后面的卷积神经网络结构小节中，读者可以看到合理地设置网络的尺寸让所有的维度都能正常工作，这件事可是相当让人头痛的。而使用零填充和遵守其他一些设计策略将会有效解决这个问题。<br></p><p><i>真实案例</i>：<a href=\"http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Krizhevsky<i class=\"icon-external\"></i></a>构架赢得了2012年的ImageNet挑战，其输入图像的尺寸是[227x227x3]。在第一个卷积层，神经元使用的感受野尺寸<img src=\"http://www.zhihu.com/equation?tex=F%3D11\" alt=\"F=11\" eeimg=\"1\">，步长<img src=\"http://www.zhihu.com/equation?tex=S%3D4\" alt=\"S=4\" eeimg=\"1\">，不使用零填充<img src=\"http://www.zhihu.com/equation?tex=P%3D0\" alt=\"P=0\" eeimg=\"1\">。因为(227-11)/4+1=55，卷积层的深度<img src=\"http://www.zhihu.com/equation?tex=K%3D96\" alt=\"K=96\" eeimg=\"1\">，则卷积层的输出数据体尺寸为[55x55x96]。55x55x96个神经元中，每个都和输入数据体中一个尺寸为[11x11x3]的区域全连接。在深度列上的96个神经元都是与输入数据体中同一个[11x11x3]区域连接，但是权重不同。有一个有趣的细节，在原论文中，说的输入图像尺寸是224x224，这是肯定错误的，因为(224-11)/4+1的结果不是整数。这件事在卷积神经网络的历史上让很多人迷惑，而这个错误到底是怎么发生的没人知道。我的猜测是Alex忘记在论文中指出自己使用了尺寸为3的额外的零填充。<br></p><p><b>参数共享</b>：在卷积层中使用参数共享是用来控制参数的数量。就用上面的例子，在第一个卷积层就有55x55x96=290,400个神经元，每个有11x11x3=364个参数和1个偏差。将这些合起来就是290400x364=105,705,600个参数。单单第一层就有这么多参数，显然这个数目是非常大的。</p><p>作一个合理的假设：如果一个特征在计算某个空间位置(x,y)的时候有用，那么它在计算另一个不同位置(x2,y2)的时候也有用。基于这个假设，可以显著地减少参数数量。换言之，就是将深度维度上一个单独的2维切片看做<b>深度切片（depth slice）</b>，比如一个数据体尺寸为[55x55x96]的就有96个深度切片，每个尺寸为[55x55]。在每个深度切片上的神经元都使用同样的权重和偏差。在这样的参数共享下，例子中的第一个卷积层就只有96个不同的权重集了，一个权重集对应一个深度切片，共有96x11x11x3=34,848个不同的权重，或34,944个参数（+96个偏差）。在每个深度切片中的55x55个权重使用的都是同样的参数。在反向传播的时候，都要计算每个神经元对它的权重的梯度，但是需要把同一个深度切片上的所有神经元对权重的梯度累加，这样就得到了对共享权重的梯度。这样，每个切片只更新一个权重集。</p><p>注意，如果在一个深度切片中的所有权重都使用同一个权重向量，那么卷积层的前向传播在每个深度切片中可以看做是在计算神经元权重和输入数据体的<b>卷积</b>（这就是“卷积层”名字由来）。这也是为什么总是将这些权重集合称为<b>滤波器（filter）</b>（或<b>卷积核（kernel）</b>），因为它们和输入进行了卷积。</p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><img src=\"http://pic3.zhimg.com/dd62e1d75bda9b592dabb91627d68aa6_b.jpg\" data-rawwidth=\"627\" data-rawheight=\"248\" class=\"origin_image zh-lightbox-thumb\" width=\"627\" data-original=\"http://pic3.zhimg.com/dd62e1d75bda9b592dabb91627d68aa6_r.jpg\">Krizhevsky等学习到的滤波器例子。这96个滤波器的尺寸都是[11x11x3]，在一个深度切片中，每个滤波器都被55x55个神经元共享。注意参数共享的假设是有道理的：如果在图像某些地方探测到一个水平的边界是很重要的，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。所以在卷积层的输出数据体的55x55个不同位置中，就没有必要重新学习去探测一个水平边界了。<img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><p>注意有时候参数共享假设可能没有意义，特别是当卷积神经网络的输入图像是一些明确的中心结构时候。这时候我们就应该期望在图片的不同位置学习到完全不同的特征。一个具体的例子就是输入图像是人脸，人脸一般都处于图片中心。你可能期望不同的特征，比如眼睛特征或者头发特征可能（也应该）会在图片的不同位置被学习。在这个例子中，通常就放松参数共享的限制，将层称为<b>局部连接层</b>（Locally-Connected Layer）。</p><p><b>Numpy例子</b>：为了让讨论更加的具体，我们用代码来展示上述思路。假设输入数据体是numpy数组<b>X</b>。那么：</p><ul><li>一个位于<b>(x,y)</b>的深度列（或纤维）将会是<b>X[x,y,:]</b>。<br></li><li>在深度为<b>d</b>处的深度切片，或激活图应该是<b>X[:,:,d]</b>。<br></li></ul><p><i>卷积层例子</i>：假设输入数据体<b>X</b>的尺寸<b>X.shape:(11,11,4)</b>，不使用零填充（<img src=\"http://www.zhihu.com/equation?tex=P%3D0\" alt=\"P=0\" eeimg=\"1\">），滤波器的尺寸是<img src=\"http://www.zhihu.com/equation?tex=F%3D5\" alt=\"F=5\" eeimg=\"1\">，步长<img src=\"http://www.zhihu.com/equation?tex=S%3D2\" alt=\"S=2\" eeimg=\"1\">。那么输出数据体的空间尺寸就是(11-5)/2+1=4，即输出数据体的宽度和高度都是4。那么在输出数据体中的激活映射（称其为<b>V</b>）看起来就是下面这样（在这个例子中，只有部分元素被计算）：</p><ul><li><b>V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0<br></b></li><li><b>V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0<br></b></li><li><b>V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0<br></b></li><li><b>V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0</b><br></li></ul><br><p>在numpy中，<b>*</b>操作是进行数组间的逐元素相乘。权重向量<b>W0</b>是该神经元的权重，<b>b0</b>是其偏差。在这里，<b>W0</b>被假设尺寸是<b>W0.shape: (5,5,4)</b>，因为滤波器的宽高是5，输入数据量的深度是4。注意在每一个点，计算点积的方式和之前的常规神经网络是一样的。同时，计算内积的时候使用的是同一个权重和偏差（因为参数共享），在宽度方向的数字每次上升2（因为步长为2）。要构建输出数据体中的第二张激活图，代码应该是：</p><ul><li><b>V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1<br></b></li><li><b>V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1<br></b></li><li><b>V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1<br></b></li><li><b>V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1</b><br></li><li><b>V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1 </b>（在y方向上）<br></li><li><b>V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1 </b>（或两个方向上同时）</li></ul><p>我们访问的是<b>V</b>的深度维度上的第二层（即index1），因为是在计算第二个激活图，所以这次试用的参数集就是<b>W1</b>了。在上面的例子中，为了简洁略去了卷积层对于输出数组<b>V</b>中其他部分的操作。还有，要记得这些卷积操作通常后面接的是ReLU层，对激活图中的每个元素做激活函数运算，这里没有显示。</p><p><b>小结</b>： 我们总结一下卷积层的性质：</p><ul><li>输入数据体的尺寸为<img src=\"http://www.zhihu.com/equation?tex=W_1%5Ctimes+H_1%5Ctimes+D_1\" alt=\"W_1\\times H_1\\times D_1\" eeimg=\"1\"></li><li>4个超参数：<ul><li>滤波器的数量<img src=\"http://www.zhihu.com/equation?tex=K\" alt=\"K\" eeimg=\"1\"></li><li>滤波器的空间尺寸<img src=\"http://www.zhihu.com/equation?tex=F\" alt=\"F\" eeimg=\"1\"></li><li>步长<img src=\"http://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"></li><li>零填充数量<img src=\"http://www.zhihu.com/equation?tex=P\" alt=\"P\" eeimg=\"1\"></li></ul></li><li>输出数据体的尺寸为<img src=\"http://www.zhihu.com/equation?tex=W_2%5Ctimes+H_2%5Ctimes+D_2\" alt=\"W_2\\times H_2\\times D_2\" eeimg=\"1\"> ，其中：</li><ul><img src=\"http://www.zhihu.com/equation?tex=W_2%3D%28W_1-F%2B2P%29%2FS%2B1\" alt=\"W_2=(W_1-F+2P)/S+1\" eeimg=\"1\"><li><img src=\"http://www.zhihu.com/equation?tex=H_2%3D%28H_1-F%2B2P%29%2FS%2B1\" alt=\"H_2=(H_1-F+2P)/S+1\" eeimg=\"1\"> （宽度和高度的计算方法相同）</li><img src=\"http://www.zhihu.com/equation?tex=D_2%3DK\" alt=\"D_2=K\" eeimg=\"1\"></ul><li>由于参数共享，每个滤波器包含<img src=\"http://www.zhihu.com/equation?tex=F%5Ccdot+F%5Ccdot+D_1\" alt=\"F\\cdot F\\cdot D_1\" eeimg=\"1\">个权重，卷积层一共有<img src=\"http://www.zhihu.com/equation?tex=F%5Ccdot+F%5Ccdot+D_1%5Ccdot+K\" alt=\"F\\cdot F\\cdot D_1\\cdot K\" eeimg=\"1\">个权重和<img src=\"http://www.zhihu.com/equation?tex=K\" alt=\"K\" eeimg=\"1\">个偏置。</li><li>在输出数据体中，第<img src=\"http://www.zhihu.com/equation?tex=d\" alt=\"d\" eeimg=\"1\">个深度切片（空间尺寸是<img src=\"http://www.zhihu.com/equation?tex=W_2%5Ctimes+H_2\" alt=\"W_2\\times H_2\" eeimg=\"1\">），用第<img src=\"http://www.zhihu.com/equation?tex=d\" alt=\"d\" eeimg=\"1\">个滤波器和输入数据进行有效卷积运算的结果（使用步长<img src=\"http://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\">），最后在加上第<img src=\"http://www.zhihu.com/equation?tex=d\" alt=\"d\" eeimg=\"1\">个偏差。</li></ul><p>对这些超参数，常见的设置是<img src=\"http://www.zhihu.com/equation?tex=F%3D3\" alt=\"F=3\" eeimg=\"1\">，<img src=\"http://www.zhihu.com/equation?tex=S%3D1\" alt=\"S=1\" eeimg=\"1\">，<img src=\"http://www.zhihu.com/equation?tex=P%3D1\" alt=\"P=1\" eeimg=\"1\">。同时设置这些超参数也有一些约定俗成的惯例和经验，可以在下面的卷积神经网络结构章节中查看。</p><p>卷积层演示：下面是一个卷积层的运行演示。因为3D数据难以可视化，所以所有的数据（输入数据体是蓝色，权重数据体是红色，输出数据体是绿色）都采取将深度切片按照列的方式排列展现。输入数据体的尺寸是<img src=\"http://www.zhihu.com/equation?tex=W_1%3D5%2CH_1%3D5%2CD_1%3D3\" alt=\"W_1=5,H_1=5,D_1=3\" eeimg=\"1\">，卷积层参数<img src=\"http://www.zhihu.com/equation?tex=K%3D2%2CF%3D3%2CS%3D2%2CP%3D1\" alt=\"K=2,F=3,S=2,P=1\" eeimg=\"1\">。就是说，有2个滤波器，滤波器的尺寸是<img src=\"http://www.zhihu.com/equation?tex=3%5Ccdot+3\" alt=\"3\\cdot 3\" eeimg=\"1\">，它们的步长是2.因此，输出数据体的空间尺寸是(5-3+2)/2+1=3。注意输入数据体使用了零填充<img src=\"http://www.zhihu.com/equation?tex=P%3D1\" alt=\"P=1\" eeimg=\"1\">，所以输入数据体外边缘一圈都是0。下面的例子在绿色的输出激活数据上循环演示，展示了其中每个元素都是先通过蓝色的输入数据和红色的滤波器逐元素相乘，然后求其总和，最后加上偏差得来。<br></p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><img src=\"http://pic2.zhimg.com/333077b83ed421d6bd53eb7a44fd5799_b.jpg\" data-rawwidth=\"734\" data-rawheight=\"711\" class=\"origin_image zh-lightbox-thumb\" width=\"734\" data-original=\"http://pic2.zhimg.com/333077b83ed421d6bd53eb7a44fd5799_r.jpg\"><p><i><b>译者注</b>：请点击图片查看动画演示。如果gif不能正确播放，请读者前往<a href=\"http://link.zhihu.com/?target=http%3A//cs231n.github.io/convolutional-networks/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">斯坦福课程官网<i class=\"icon-external\"></i></a>查看此演示。</i><br></p><br><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><p><b>用矩阵乘法实现</b>：卷积运算本质上就是在滤波器和输入数据的局部区域间做点积。卷积层的常用实现方式就是利用这一点，将卷积层的前向传播变成一个巨大的矩阵乘法：</p><ol><li>输入图像的局部区域被<b>im2col</b>操作拉伸为列。比如，如果输入是[227x227x3]，要与尺寸为11x11x3的滤波器以步长为4进行卷积，就取输入中的[11x11x3]数据块，然后将其拉伸为长度为11x11x3=363的列向量。重复进行这一过程，因为步长为4，所以输出的宽高为(227-11)/4+1=55，所以得到<i>im2col</i>操作的输出矩阵<b>X_col</b>的尺寸是[363x3025]，其中每列是拉伸的感受野，共有55x55=3,025个。注意因为感受野之间有重叠，所以输入数据体中的数字在不同的列中可能有重复。<br></li><li>卷积层的权重也同样被拉伸成行。举例，如果有96个尺寸为[11x11x3]的滤波器，就生成一个矩阵<b>W_row</b>，尺寸为[96x363]。<br></li><li>现在卷积的结果和进行一个大矩阵乘<b>np.dot(W_row, X_col)</b>是等价的了，能得到每个滤波器和每个感受野间的点积。在我们的例子中，这个操作的输出是[96x3025]，给出了每个滤波器在每个位置的点积输出。<br></li><li>结果最后必须被重新变为合理的输出尺寸[55x55x96]。</li></ol><p>这个方法的缺点就是占用内存太多，因为在输入数据体中的某些值在<b>X_col</b>中被复制了多次。但是，其优点是矩阵乘法有非常多的高效实现方式，我们都可以使用（比如常用的<a href=\"http://link.zhihu.com/?target=http%3A//www.netlib.org/blas/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">BLAS<i class=\"icon-external\"></i></a> API）。还有，同样的<i>im2col</i>思路可以用在汇聚操作中。</p><p>反向传播：卷积操作的反向传播（同时对于数据和权重）还是一个卷积（但是是和空间上翻转的滤波器）。使用一个1维的例子比较容易演示。<br></p><p><b>1x1卷积</b>：一些论文中使用了1x1的卷积，这个方法最早是在论文<a href=\"http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1312.4400\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Network in Network<i class=\"icon-external\"></i></a>中出现。人们刚开始看见这个1x1卷积的时候比较困惑，尤其是那些具有信号处理专业背景的人。因为信号是2维的，所以1x1卷积就没有意义。但是，在卷积神经网络中不是这样，因为这里是对3个维度进行操作，滤波器和输入数据体的深度是一样的。比如，如果输入是[32x32x3]，那么1x1卷积就是在高效地进行3维点积（因为输入深度是3个通道）。<br></p><p><b>扩张卷积</b>：最近一个研究（<a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.07122\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Fisher Yu和Vladlen Koltun的论文<i class=\"icon-external\"></i></a>）给卷积层引入了一个新的叫<i>扩张（dilation）</i>的超参数。到目前为止，我们只讨论了卷积层滤波器是连续的情况。但是，让滤波器中元素之间有间隙也是可以的，这就叫做扩张。举例，在某个维度上滤波器<b>w</b>的尺寸是3，那么计算输入<b>x</b>的方式是：<b>w[0]*x[0] + w[1]*x[1] + w[2]*x[2]</b>，此时扩张为0。如果扩张为1，那么计算为： <b>w[0]*x[0] + w[1]*x[2] + w[2]*x[4]</b>。换句话说，操作中存在1的间隙。在某些设置中，扩张卷积与正常卷积结合起来非常有用，因为在很少的层数内更快地汇集输入图片的大尺度特征。比如，如果上下重叠2个3x3的卷积层，那么第二个卷积层的神经元的感受野是输入数据体中5x5的区域（可以成这些神经元的<i>有效感受野</i>是5x5）。如果我们对卷积进行扩张，那么这个有效感受野就会迅速增长。<br></p><br><h4>汇聚层</h4><p>通常，在连续的卷积层之间会周期性地插入一个汇聚层。它的作用是逐渐降低数据体的空间尺寸，这样的话就能减少网络中参数的数量，使得计算资源耗费变少，也能有效控制过拟合。汇聚层使用MAX操作，对输入数据体的每一个深度切片独立进行操作，改变它的空间尺寸。最常见的形式是汇聚层使用尺寸2x2的滤波器，以步长为2来对每个深度切片进行降采样，将其中75%的激活信息都丢掉。每个MAX操作是从4个数字中取最大值（也就是在深度切片中某个2x2的区域）。深度保持不变。汇聚层的一些公式：</p><ul><li>输入数据体尺寸<img src=\"http://www.zhihu.com/equation?tex=W_1%5Ccdot+H_1%5Ccdot+D_1\" alt=\"W_1\\cdot H_1\\cdot D_1\" eeimg=\"1\"><br></li><li>有两个超参数：<br></li><ul><li>空间大小<img src=\"http://www.zhihu.com/equation?tex=F\" alt=\"F\" eeimg=\"1\"></li><li>步长<img src=\"http://www.zhihu.com/equation?tex=S\" alt=\"S\" eeimg=\"1\"></li></ul><li>输出数据体尺寸<img src=\"http://www.zhihu.com/equation?tex=W_2%5Ccdot+H_2%5Ccdot+D_2\" alt=\"W_2\\cdot H_2\\cdot D_2\" eeimg=\"1\">，其中</li><img src=\"http://www.zhihu.com/equation?tex=+W_2%3D%28W_1-F%29%2FS%2B1\" alt=\" W_2=(W_1-F)/S+1\" eeimg=\"1\"><br><img src=\"http://www.zhihu.com/equation?tex=H_2%3D%28H_1-F%29%2FS%2B1\" alt=\"H_2=(H_1-F)/S+1\" eeimg=\"1\"><br><img src=\"http://www.zhihu.com/equation?tex=D_2%3DD_1\" alt=\"D_2=D_1\" eeimg=\"1\"><br><li>因为对输入进行的是固定函数计算，所以没有引入参数<br></li><li>在汇聚层中很少使用零填充<br></li></ul><p>在实践中，最大汇聚层通常只有两种形式：一种是<img src=\"http://www.zhihu.com/equation?tex=F%3D3%2CS%3D2\" alt=\"F=3,S=2\" eeimg=\"1\">，也叫重叠汇聚（overlapping pooling），另一个更常用的是<img src=\"http://www.zhihu.com/equation?tex=F%3D2%2CS%3D2\" alt=\"F=2,S=2\" eeimg=\"1\">。对更大感受野进行汇聚需要的汇聚尺寸也更大，而且往往对网络有破坏性。</p><p><b>普通汇聚（General Pooling）</b>：除了最大汇聚，汇聚单元还可以使用其他的函数，比如<i>平均</i>汇聚<i>（average pooling）</i>或<i>L-2范式</i>汇聚<i>（L2-norm pooling）</i>。平均汇聚历史上比较常用，但是现在已经很少使用了。因为实践证明，最大汇聚的效果比平均汇聚要好。</p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><p><img src=\"http://pic4.zhimg.com/641c8846abcb02d35938660cf96cef1b_b.jpg\" data-rawwidth=\"1349\" data-rawheight=\"406\" class=\"origin_image zh-lightbox-thumb\" width=\"1349\" data-original=\"http://pic4.zhimg.com/641c8846abcb02d35938660cf96cef1b_r.jpg\"><br>汇聚层在输入数据体的每个深度切片上，独立地对其进行空间上的降采样。左边：本例中，输入数据体尺寸[224x224x64]被降采样到了[112x112x64]，采取的滤波器尺寸是2，步长为2，而深度不变。右边：最常用的降采样操作是取最大值，也就是最大汇聚，这里步长为2，每个取最大值操作是从4个数字中选取（即2x2的方块区域中）。</p><img src=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_b.png\" data-rawwidth=\"1014\" data-rawheight=\"3\" class=\"origin_image zh-lightbox-thumb\" width=\"1014\" data-original=\"http://pic1.zhimg.com/307530cfd15f5ca2461a2b6f633f93b8_r.png\"><p><b>反向传播：</b>回顾一下反向传播的内容，其中<img src=\"http://www.zhihu.com/equation?tex=max%28x%2Cy%29\" alt=\"max(x,y)\" eeimg=\"1\">函数的反向传播可以简单理解为将梯度只沿最大的数回传。因此，在向前传播经过汇聚层的时候，通常会把池中最大元素的索引记录下来（有时这个也叫作<b>道岔（switches）</b>），这样在反向传播的时候梯度的路由就很高效。</p><p><b>不使用汇聚层</b>：很多人不喜欢汇聚操作，认为可以不使用它。比如在<a href=\"http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.6806\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Striving for Simplicity: The All Convolutional Net<i class=\"icon-external\"></i></a>一文中，提出使用一种只有重复的卷积层组成的结构，抛弃汇聚层。通过在卷积层中使用更大的步长来降低数据体的尺寸。有发现认为，在训练一个良好的生成模型时，弃用汇聚层也是很重要的。比如变化自编码器（VAEs：variational autoencoders）和生成性对抗网络（GANs：generative adversarial networks）。现在看起来，未来的卷积网络结构中，无汇聚层的结构不太可能扮演重要的角色。</p><br><h4>归一化层</h4><p>在卷积神经网络的结构中，提出了很多不同类型的归一化层，有时候是为了实现在生物大脑中观测到的抑制机制。但是这些层渐渐都不再流行，因为实践证明它们的效果即使存在，也是极其有限的。对于不同类型的归一化层，可以看看Alex Krizhevsky的关于<a href=\"http://link.zhihu.com/?target=https%3A//code.google.com/p/cuda-convnet/wiki/LayerParams%23Local_response_normalization_layer_%28same_map%29\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">cuda-convnet library API<i class=\"icon-external\"></i></a>的讨论。<br></p><br><h4>全连接层</h4><p>在全连接层中，神经元对于前一层中的所有激活数据是全部连接的，这个常规神经网络中一样。它们的激活可以先用矩阵乘法，再加上偏差。更多细节请查看<i>神经网络</i>章节。</p><br><h2>把全连接层转化成卷积层</h2><p>全连接层和卷积层之间唯一的不同就是卷积层中的神经元只与输入数据中的一个局部区域连接，并且在卷积列中的神经元共享参数。然而在两类层中，神经元都是计算点积，所以它们的函数形式是一样的。因此，将此两者相互转化是可能的：</p><ul><li>对于任一个卷积层，都存在一个能实现和它一样的前向传播函数的全连接层。权重矩阵是一个巨大的矩阵，除了某些特定块（这是因为有局部连接），其余部分都是零。而在其中大部分块中，元素都是相等的（因为参数共享）。<br></li><li>相反，任何全连接层都可以被转化为卷积层。比如，一个<img src=\"http://www.zhihu.com/equation?tex=K%3D4096\" alt=\"K=4096\" eeimg=\"1\">的全连接层，输入数据体的尺寸是<img src=\"http://www.zhihu.com/equation?tex=7%5Ctimes+7%5Ctimes+512\" alt=\"7\\times 7\\times 512\" eeimg=\"1\">，这个全连接层可以被等效地看做一个<img src=\"http://www.zhihu.com/equation?tex=F%3D7%2CP%3D0%2CS%3D1%2CK%3D4096\" alt=\"F=7,P=0,S=1,K=4096\" eeimg=\"1\">的卷积层。换句话说，就是将滤波器的尺寸设置为和输入数据体的尺寸一致了。因为只有一个单独的深度列覆盖并滑过输入数据体，所以输出将变成<img src=\"http://www.zhihu.com/equation?tex=1%5Ctimes+1%5Ctimes+4096\" alt=\"1\\times 1\\times 4096\" eeimg=\"1\">，这个结果就和使用初始的那个全连接层一样了。<br></li></ul><br><b>全连接层转化为卷积层</b>：在两种变换中，将全连接层转化为卷积层在实际运用中更加有用。假设一个卷积神经网络的输入是224x224x3的图像，一系列的卷积层和汇聚层将图像数据变为尺寸为7x7x512的激活数据体（在AlexNet中就是这样，通过使用5个汇聚层来对输入数据进行空间上的降采样，每次尺寸下降一半，所以最终空间尺寸为224/2/2/2/2/2=7）。从这里可以看到，AlexNet使用了两个尺寸为4096的全连接层，最后一个有1000个神经元的全连接层用于计算分类评分。我们可以将这3个全连接层中的任意一个转化为卷积层：<br><ul><li>针对第一个连接区域是[7x7x512]的全连接层，令其滤波器尺寸为<img src=\"http://www.zhihu.com/equation?tex=F%3D7\" alt=\"F=7\" eeimg=\"1\">，这样输出数据体就为[1x1x4096]了。<br></li><li>针对第二个全连接层，令其滤波器尺寸为<img src=\"http://www.zhihu.com/equation?tex=F%3D1\" alt=\"F=1\" eeimg=\"1\">，这样输出数据体为[1x1x4096]。<br></li><li>对最后一个全连接层也做类似的，令其<img src=\"http://www.zhihu.com/equation?tex=F%3D1\" alt=\"F=1\" eeimg=\"1\">，最终输出为[1x1x1000]<br></li></ul><p>实际操作中，每次这样的变换都需要把全连接层的权重W重塑成卷积层的滤波器。那么这样的转化有什么作用呢？它在下面的情况下可以更高效：让卷积网络在一张更大的输入图片上滑动（<i><b>译者注</b>：即把一张更大的图片的不同区域都分别带入到卷积网络，得到每个区域的得分</i>），得到多个输出，这样的转化可以让我们在单个向前传播的过程中完成上述的操作。</p><p>举个例子，如果我们想让224x224尺寸的浮窗，以步长为32在384x384的图片上滑动，把每个经停的位置都带入卷积网络，最后得到6x6个位置的类别得分。上述的把全连接层转换成卷积层的做法会更简便。如果224x224的输入图片经过卷积层和汇聚层之后得到了[7x7x512]的数组，那么，384x384的大图片直接经过同样的卷积层和汇聚层之后会得到[12x12x512]的数组（因为途径5个汇聚层，尺寸变为384/2/2/2/2/2 = 12）。然后再经过上面由3个全连接层转化得到的3个卷积层，最终得到[6x6x1000]的输出（因为(12 - 7)/1 + 1 = 6）。这个结果正是浮窗在原图经停的6x6个位置的得分！（<i><b>译者注</b>：这一段的翻译与原文不同，经过了译者较多的修改，使更容易理解</i>）</p><blockquote>面对384x384的图像，让（含全连接层）的初始卷积神经网络以32像素的步长独立对图像中的224x224块进行多次评价，其效果和使用把全连接层变换为卷积层后的卷积神经网络进行一次前向传播是一样的。</blockquote><p>自然，相较于使用被转化前的原始卷积神经网络对所有36个位置进行迭代计算，使用转化后的卷积神经网络进行一次前向传播计算要高效得多，因为36次计算都在共享计算资源。这一技巧在实践中经常使用，一次来获得更好的结果。比如，通常将一张图像尺寸变得更大，然后使用变换后的卷积神经网络来对空间上很多不同位置进行评价得到分类评分，然后在求这些分值的平均值。</p><p>最后，如果我们想用步长小于32的浮窗怎么办？用多次的向前传播就可以解决。比如我们想用步长为16的浮窗。那么先使用原图在转化后的卷积网络执行向前传播，然后分别沿宽度，沿高度，最后同时沿宽度和高度，把原始图片分别平移16个像素，然后把这些平移之后的图分别带入卷积网络。（<i><b>译者注</b>：这一段的翻译与原文不同，经过了译者较多的修改，使更容易理解</i>）</p><ul><li><a href=\"http://link.zhihu.com/?target=https%3A//github.com/BVLC/caffe/blob/master/examples/net_surgery.ipynb\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Net Surgery<i class=\"icon-external\"></i></a>上一个使用Caffe演示如何在进行变换的IPython Note教程。<br></li></ul><br><br><h3><b>卷积神经网络的结构</b></h3><p>卷积神经网络通常是由三种层构成：卷积层，汇聚层（除非特别说明，一般就是最大值汇聚）和全连接层（简称FC）。ReLU激活函数也应该算是是一层，它逐元素地进行激活函数操作。在本节中将讨论在卷积神经网络中这些层通常是如何组合在一起的。</p><br><h4>层的排列规律</h4><p>卷积神经网络最常见的形式就是将一些卷积层和ReLU层放在一起，其后紧跟汇聚层，然后重复如此直到图像在空间上被缩小到一个足够小的尺寸，在某个地方过渡成成全连接层也较为常见。最后的全连接层得到输出，比如分类评分等。换句话说，最常见的卷积神经网络结构如下：</p><p><b>INPUT -&amp;gt; [[CONV -&amp;gt; RELU]*N -&amp;gt; POOL?]*M -&amp;gt; [FC -&amp;gt; RELU]*K -&amp;gt; FC</b></p><p>其中<b>*</b>指的是重复次数，<b>POOL?</b>指的是一个可选的汇聚层。其中<b>N &amp;gt;=0</b>,通常<b>N&amp;lt;=3</b>,<b>M&amp;gt;=0</b>,<b>K&amp;gt;=0</b>,通常<b>K&amp;lt;3</b>。例如，下面是一些常见的网络结构规律：</p><ul><li><b>INPUT -&amp;gt; FC</b>,实现一个线性分类器，此处<b>N = M = K = 0</b>。<br></li><li><b>INPUT -&amp;gt; CONV -&amp;gt; RELU -&amp;gt; FC</b><br></li><li><b>INPUT -&amp;gt; [CONV -&amp;gt; RELU -&amp;gt; POOL]*2 -&amp;gt; FC -&amp;gt; RELU -&amp;gt; FC</b>。此处在每个汇聚层之间有一个卷积层。<br></li><li><b>INPUT -&amp;gt; [CONV -&amp;gt; RELU -&amp;gt; CONV -&amp;gt; RELU -&amp;gt; POOL]*3 -&amp;gt; [FC -&amp;gt; RELU]*2 -&amp;gt; FC</b>。此处每个汇聚层前有两个卷积层，这个思路适用于更大更深的网络，因为在执行具有破坏性的汇聚操作前，多重的卷积层可以从输入数据中学习到更多的复杂特征。<br></li></ul><p><i>几个小滤波器卷积层的组合比一个大滤波器卷积层好</i>：假设你一层一层地重叠了3个3x3的卷积层（层与层之间有非线性激活函数）。在这个排列下，第一个卷积层中的每个神经元都对输入数据体有一个3x3的视野。第二个卷积层上的神经元对第一个卷积层有一个3x3的视野，也就是对输入数据体有5x5的视野。同样，在第三个卷积层上的神经元对第二个卷积层有3x3的视野，也就是对输入数据体有7x7的视野。假设不采用这3个3x3的卷积层，二是使用一个单独的有7x7的感受野的卷积层，那么所有神经元的感受野也是7x7，但是就有一些缺点。首先，多个卷积层与非线性的激活层交替的结构，比单一卷积层的结构更能提取出深层的更好的特征。其次，假设所有的数据有<img src=\"http://www.zhihu.com/equation?tex=C\" alt=\"C\" eeimg=\"1\">个通道，那么单独的7x7卷积层将会包含<img src=\"http://www.zhihu.com/equation?tex=C%5Ctimes+%287%5Ctimes+7%5Ctimes+C%29%3D49C%5E2\" alt=\"C\\times (7\\times 7\\times C)=49C^2\" eeimg=\"1\">个参数，而3个3x3的卷积层的组合仅有<img src=\"http://www.zhihu.com/equation?tex=3%5Ctimes+%28C%5Ctimes+%283%5Ctimes+3%5Ctimes+C%29%29%3D27C%5E2\" alt=\"3\\times (C\\times (3\\times 3\\times C))=27C^2\" eeimg=\"1\">个参数。直观说来，最好选择带有小滤波器的卷积层组合，而不是用一个带有大的滤波器的卷积层。前者可以表达出输入数据中更多个强力特征，使用的参数也更少。唯一的不足是，在进行反向传播时，中间的卷积层可能会导致占用更多的内存。</p><p>最新进展：传统的将层按照线性进行排列的方法已经受到了挑战，挑战来自谷歌的Inception结构和微软亚洲研究院的残差网络（Residual Net）结构。这两个网络（下文案例学习小节中有细节）的特征更加复杂，连接结构也不同。</p><br><h4>层的尺寸设置规律</h4><p>到现在为止，我们都没有提及卷积神经网络中每层的超参数的使用。现在先介绍设置结构尺寸的一般性规则，然后根据这些规则进行讨论：</p><p><b>输入层</b>（包含图像的）应该能被2整除很多次。常用数字包括32（比如CIFAR-10），64，96（比如STL-10）或224（比如ImageNet卷积神经网络），384和512。</p><p><b>卷积层</b>应该使用小尺寸滤波器（比如3x3或最多5x5），使用步长<img src=\"http://www.zhihu.com/equation?tex=S%3D1\" alt=\"S=1\" eeimg=\"1\">。还有一点非常重要，就是对输入数据进行零填充，这样卷积层就不会改变输入数据在空间维度上的尺寸。比如，当<img src=\"http://www.zhihu.com/equation?tex=F%3D3\" alt=\"F=3\" eeimg=\"1\">，那就使用<img src=\"http://www.zhihu.com/equation?tex=P%3D1\" alt=\"P=1\" eeimg=\"1\">来保持输入尺寸。当<img src=\"http://www.zhihu.com/equation?tex=F%3D5%2CP%3D2\" alt=\"F=5,P=2\" eeimg=\"1\">，一般对于任意<img src=\"http://www.zhihu.com/equation?tex=F\" alt=\"F\" eeimg=\"1\">，当<img src=\"http://www.zhihu.com/equation?tex=P%3D%28F-1%29%2F2\" alt=\"P=(F-1)/2\" eeimg=\"1\">的时候能保持输入尺寸。如果必须使用更大的滤波器尺寸（比如7x7之类），通常只用在第一个面对原始图像的卷积层上。</p><br><p><b>汇聚层</b>负责对输入数据的空间维度进行降采样。最常用的设置是用用2x2感受野（即<img src=\"http://www.zhihu.com/equation?tex=F%3D2\" alt=\"F=2\" eeimg=\"1\">）的最大值汇聚，步长为2（<img src=\"http://www.zhihu.com/equation?tex=S%3D2\" alt=\"S=2\" eeimg=\"1\">）。注意这一操作将会把输入数据中75%的激活数据丢弃（因为对宽度和高度都进行了2的降采样）。另一个不那么常用的设置是使用3x3的感受野，步长为2。最大值汇聚的感受野尺寸很少有超过3的，因为汇聚操作过于激烈，易造成数据信息丢失，这通常会导致算法性能变差。</p><p><i>减少尺寸设置的问题</i>：上文中展示的两种设置是很好的，因为所有的卷积层都能保持其输入数据的空间尺寸，汇聚层只负责对数据体从空间维度进行降采样。如果使用的步长大于1并且不对卷积层的输入数据使用零填充，那么就必须非常仔细地监督输入数据体通过整个卷积神经网络结构的过程，确认所有的步长和滤波器都尺寸互相吻合，卷积神经网络的结构美妙对称地联系在一起。</p><br><p><i>为什么在卷积层使用1的步长</i>？在实际应用中，更小的步长效果更好。上文也已经提过，步长为1可以让空间维度的降采样全部由汇聚层负责，卷积层只负责对输入数据体的深度进行变换。</p><p><i>为何使用零填充</i>？使用零填充除了前面提到的可以让卷积层的输出数据保持和输入数据在空间维度的不变，还可以提高算法性能。如果卷积层值进行卷积而不进行零填充，那么数据体的尺寸就会略微减小，那么图像边缘的信息就会过快地损失掉。</p><p><i>因为内存限制所做的妥协</i>：在某些案例（尤其是早期的卷积神经网络结构）中，基于前面的各种规则，内存的使用量迅速飙升。例如，使用64个尺寸为3x3的滤波器对224x224x3的图像进行卷积，零填充为1，得到的激活数据体尺寸是[224x224x64]。这个数量就是一千万的激活数据，或者就是72MB的内存（每张图就是这么多，激活函数和梯度都是）。因为GPU通常因为内存导致性能瓶颈，所以做出一些妥协是必须的。在实践中，人们倾向于在网络的第一个卷积层做出妥协。例如，可以妥协可能是在第一个卷积层使用步长为2，尺寸为7x7的滤波器（比如在ZFnet中）。在AlexNet中，滤波器的尺寸的11x11，步长为4。</p><br><h4>案例学习</h4><p>下面是卷积神经网络领域中比较有名的几种结构：</p><ul><li><b>LeNet</b>： 第一个成功的卷积神经网络应用，是Yann LeCun在上世纪90年代实现的。当然，最著名还是被应用在识别数字和邮政编码等的<a href=\"http://link.zhihu.com/?target=http%3A//yann.lecun.com/exdb/publis/pdf/lecun-98.pdf\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">LeNet<i class=\"icon-external\"></i></a>结构。</li><li><b>AlexNet</b>：<a href=\"http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">AlexNet<i class=\"icon-external\"></i></a>卷积神经网络在计算机视觉领域中受到欢迎，它由Alex Krizhevsky，Ilya Sutskever和Geoff Hinton实现。AlexNet在2012年的<a href=\"http://link.zhihu.com/?target=http%3A//www.image-net.org/challenges/LSVRC/2014/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ImageNet ILSVRC 竞赛<i class=\"icon-external\"></i></a>中夺冠，性能远远超出第二名（16%的top5错误率，第二名是26%的top5错误率）。这个网络的结构和LeNet非常类似，但是更深更大，并且使用了层叠的卷积层来获取特征（之前通常是只用一个卷积层并且在其后马上跟着一个汇聚层）。</li><li><b>ZF Net</b>：Matthew Zeiler和Rob Fergus发明的网络在ILSVRC 2013比赛中夺冠，它被称为 <a href=\"http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1311.2901\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ZFNet<i class=\"icon-external\"></i></a>（Zeiler &amp;amp; Fergus Net的简称）。它通过修改结构中的超参数来实现对AlexNet的改良，具体说来就是增加了中间卷积层的尺寸，让第一层的步长和滤波器尺寸更小。</li><li><b>GoogLeNet</b>：ILSVRC 2014的胜利者是谷歌的<a href=\"http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1409.4842\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Szeged等<i class=\"icon-external\"></i></a>实现的卷积神经网络。它主要的贡献就是实现了一个<i>奠基模块</i>，它能够显著地减少网络中参数的数量（AlexNet中有60M，该网络中只有4M）。还有，这个论文中没有使用卷积神经网络顶部使用全连接层，而是使用了一个平均汇聚，把大量不是很重要的参数都去除掉了。GooLeNet还有几种改进的版本，最新的一个是<a href=\"http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1602.07261\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Inception-v4<i class=\"icon-external\"></i></a>。</li><li><b>VGGNet</b>：ILSVRC 2014的第二名是Karen Simonyan和 Andrew Zisserman实现的卷积神经网络，现在称其为<a href=\"http://link.zhihu.com/?target=http%3A//www.robots.ox.ac.uk/%7Evgg/research/very_deep/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">VGGNet<i class=\"icon-external\"></i></a>。它主要的贡献是展示出网络的深度是算法优良性能的关键部分。他们最好的网络包含了16个卷积/全连接层。网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的汇聚。他们的<a href=\"http://link.zhihu.com/?target=http%3A//www.robots.ox.ac.uk/%7Evgg/research/very_deep/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">预训练模型<i class=\"icon-external\"></i></a>是可以在网络上获得并在Caffe中使用的。VGGNet不好的一点是它耗费更多计算资源，并且使用了更多的参数，导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。后来发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量。</li><li><b>ResNet</b>：<a href=\"http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1512.03385\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">残差网络<i class=\"icon-external\"></i></a>（Residual Network）是ILSVRC2015的胜利者，由何恺明等实现。它使用了特殊的<i>跳跃链接</i>，大量使用了<a href=\"http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.03167\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">批量归一化<i class=\"icon-external\"></i></a>（batch normalization）。这个结构同样在最后没有使用全连接层。读者可以查看何恺明的的演讲（<a href=\"http://link.zhihu.com/?target=https%3A//github.com/gcr/torch-residual-networks\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">视频<i class=\"icon-external\"></i></a>，<a href=\"http://link.zhihu.com/?target=https%3A//github.com/gcr/torch-residual-networks\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">PPT<i class=\"icon-external\"></i></a>），以及一些使用Torch重现网络的<a href=\"http://link.zhihu.com/?target=https%3A//github.com/gcr/torch-residual-networks\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">实验<i class=\"icon-external\"></i></a>。ResNet当前最好的卷积神经网络模型（2016年五月）。何开明等最近的工作是对原始结构做一些优化，可以看论文<a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1603.05027\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Identity Mappings in Deep Residual Networks<i class=\"icon-external\"></i></a>，2016年3月发表。</li></ul><p><b>VGGNet的细节：</b>我们进一步对<a href=\"http://link.zhihu.com/?target=http%3A//www.robots.ox.ac.uk/%7Evgg/research/very_deep/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">VGGNet<i class=\"icon-external\"></i></a>的细节进行分析学习。整个VGGNet中的卷积层都是以步长为1进行3x3的卷积，使用了1的零填充，汇聚层都是以步长为2进行了2x2的最大值汇聚。可以写出处理过程中每一步数据体尺寸的变化，然后对数据尺寸和整体权重的数量进行查看：</p><br><div class=\"highlight\"><pre><code class=\"language-text\"><span></span>INPUT: [224x224x3]        memory:  224*224*3=150K   weights: 0\nCONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*3)*64 = 1,728\nCONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*64)*64 = 36,864\nPOOL2: [112x112x64]  memory:  112*112*64=800K   weights: 0\nCONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*64)*128 = 73,728\nCONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*128)*128 = 147,456\nPOOL2: [56x56x128]  memory:  56*56*128=400K   weights: 0\nCONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*128)*256 = 294,912\nCONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824\nCONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824\nPOOL2: [28x28x256]  memory:  28*28*256=200K   weights: 0\nCONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*256)*512 = 1,179,648\nCONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296\nCONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296\nPOOL2: [14x14x512]  memory:  14*14*512=100K   weights: 0\nCONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\nCONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\nCONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\nPOOL2: [7x7x512]  memory:  7*7*512=25K  weights: 0\nFC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 = 102,760,448\nFC: [1x1x4096]  memory:  4096  weights: 4096*4096 = 16,777,216\nFC: [1x1x1000]  memory:  1000 weights: 4096*1000 = 4,096,000\n\nTOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)\nTOTAL params: 138M parameters\n</code></pre></div><p>注意，大部分的内存和计算时间都被前面的卷积层占用，大部分的参数都用在后面的全连接层，这在卷积神经网络中是比较常见的。在这个例子中，全部参数有140M，但第一个全连接层就包含了100M的参数。</p><br><h2>计算上的考量</h2><p>在构建卷积神经网络结构时，最大的瓶颈是内存瓶颈。大部分现代GPU的内存是3/4/6GB，最好的GPU大约有12GB的内存。要注意三种内存占用来源：</p><ul><li>来自中间数据体尺寸：卷积神经网络中的每一层中都有激活数据体的原始数值，以及损失函数对它们的梯度（和激活数据体尺寸一致）。通常，大部分激活数据都是在网络中靠前的层中（比如第一个卷积层）。在训练时，这些数据需要放在内存中，因为反向传播的时候还会用到。但是在测试时可以聪明点：让网络在测试运行时候每层都只存储当前的激活数据，然后丢弃前面层的激活数据，这样就能减少巨大的激活数据量。<br></li><li>来自参数尺寸：即整个网络的参数的数量，在反向传播时它们的梯度值，以及使用momentum、Adagrad或RMSProp等方法进行最优化时的每一步计算缓存。因此，存储参数向量的内存通常需要在参数向量的容量基础上乘以3或者更多。<br></li><li>卷积神经网络实现还有各种零散的内存占用，比如成批的训练数据，扩充的数据等等。<br></li></ul><p>一旦对于所有这些数值的数量有了一个大略估计（包含激活数据，梯度和各种杂项），数量应该转化为以GB为计量单位。把这个值乘以4，得到原始的字节数（因为每个浮点数占用4个字节，如果是双精度浮点数那就是占用8个字节），然后多次除以1024分别得到占用内存的KB，MB，最后是GB计量。如果你的网络工作得不好，一个常用的方法是降低批尺寸（batch size），因为绝大多数的内存都是被激活数据消耗掉了。</p><br><br><h2><b>拓展资源</b></h2><p>和实践相关的拓展资源：</p><ul><li><a href=\"http://link.zhihu.com/?target=https%3A//github.com/soumith/convnet-benchmarks\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Soumith benchmarks for CONV performance<i class=\"icon-external\"></i></a></li><li><a href=\"http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">ConvNetJS CIFAR-10 demo<i class=\"icon-external\"></i></a> 可以让你在服务器上实时地调试卷积神经网络的结构，观察计算结果。</li><li><a href=\"http://link.zhihu.com/?target=http%3A//caffe.berkeleyvision.org/\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">Caffe<i class=\"icon-external\"></i></a>，一个流行的卷积神经网络库。</li><li><a href=\"http://link.zhihu.com/?target=http%3A//torch.ch/blog/2016/02/04/resnets.html\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\">State of the art ResNets in Torch7<i class=\"icon-external\"></i></a></li></ul><p><b>卷积神经网络笔记</b>结束。<br></p><br><br><h2><b>译者反馈</b></h2><ol><li><b>转载须全文转载且注明原文链接，否则保留维权权利</b>；<br></li><li>各位知友如果发现翻译不当的地方，欢迎通过评论和私信等方式批评指正，我们会在文中补充感谢贡献者；</li><li>CS231n的翻译进入尾声，<b>欢迎知友们建议后续的翻译方向</b>；</li><li>本文最初的译稿由杜客和我于五月底完成，为了保证质量，我们两人每人翻译了一个版本，然后结合两个译稿的长处来编辑最终的版本。本文的绝大部分都保留了杜客的版本，在少数段落和语句上采用了我的版本。整个翻译小组在校对工作上付出了很多努力，为译稿提出了近百条修改意见，使得译稿逐渐完善。杜客为了鼓励新手，让此文以我的ID投稿发表。这是我第一次发表文章，非常激动^_^；</li><li>感谢知友@<a href=\"https://www.zhihu.com/people/chen-yi-91-27\" class=\"internal\">陈一</a> ， @<a href=\"https://www.zhihu.com/people/maxint\" class=\"internal\">maxint</a>和 @<a class=\"internal\" href=\"https://www.zhihu.com/people/liu-da-xu\">刘大絮</a>对细节的指正；</li><li>感谢知友@<a href=\"https://www.zhihu.com/people/zhong-xiao-qi-98\" class=\"internal\">钟小祺</a> 对翻译细节的建议。</li></ol>","state":"published","sourceUrl":"","pageCommentsCount":0,"canComment":true,"snapshotUrl":"","slug":22038289,"publishedTime":"2016-08-20T12:24:22+08:00","url":"/p/22038289","title":"CS231n课程笔记翻译：卷积神经网络笔记","summary":"<b>译者注</b>：本文翻译自斯坦福CS231n课程笔记<a href=\"http://cs231n.github.io/convolutional-networks/\" data-title=\"ConvNet notes\" class=\"\" data-editable=\"true\">ConvNet notes</a>，由课程教师<a href=\"https://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/\" class=\"\" data-editable=\"true\" data-title=\"Andrej Karpathy\">Andrej Karpathy</a>授权进行翻译。本篇教程由<a href=\"https://www.zhihu.com/people/du-ke\" data-editable=\"true\" data-title=\"杜客\" class=\"\">杜客</a>和<a href=\"https://www.zhihu.com/people/hmonkey\" data-editable=\"true\" data-title=\"猴子\">猴子</a>翻译完成，<a href=\"https://www.zhihu.com/people/kun-kun-97-81\" class=\"\" data-editable=\"true\" data-title=\"堃堃\">堃堃</a>和<a href=\"https://www.zhihu.com/people/li-yi-ying-73\" class=\"\" data-editable=\"true\" data-title=\"李艺颖\">李艺颖</a>进行校对修改。 原文如下内容列表：<b>结构概述</b><b>用来构建卷积神经网络的各种层</b> 卷积层汇聚层归一化层全连接层将全连…","reviewingCommentsCount":0,"meta":{"previous":null,"next":null},"commentPermission":"anyone","commentsCount":0,"likesCount":0},"next":{"isTitleImageFullScreen":false,"rating":"none","titleImage":"https://pic2.zhimg.com/6f589df38509d14f839737645322a011_r.jpg","links":{"comments":"/api/posts/22143664/comments"},"topics":[{"url":"https://www.zhihu.com/topic/19551275","id":"19551275","name":"人工智能"},{"url":"https://www.zhihu.com/topic/19813032","id":"19813032","name":"深度学习（Deep Learning）"},{"url":"https://www.zhihu.com/topic/19556664","id":"19556664","name":"科技"}],"adminClosedComment":false,"href":"/api/posts/22143664","excerptTitle":"","author":{"bio":"Independent Researcher of Deep Learning","isFollowing":false,"hash":"23deec836a24f295500a6d740011359c","uid":654375804428095500,"isOrg":false,"slug":"flood-sung","isFollowed":false,"description":"本人已委托“维权骑士”（rightknights.com)为我的文章进行维权行动，如需转载前往https://rightknights.com/material/author?id=2960 获取合法授权。联系本人有问题直接问，除了技术问题之外，其余一律不答！谢谢！","name":"Flood Sung","profileUrl":"https://www.zhihu.com/people/flood-sung","avatar":{"id":"73a71f47d66e280735a6c786131bdfe2","template":"https://pic3.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},"column":{"slug":"intelligentunit","name":"智能单元"},"content":"<h2>1 前言</h2><p>众所周知，在深度学习中我们使用反向传播算法进行训练。可能在任意一门深度学习课程中，反向传播都是必学的内容。我们使用反向传播计算每个参数的梯度，从而能够使用各种梯度下降方法SGD，Adam，RMSProp等来更新参数。基本上可以说反向传播算法是深度学习算法的基础。目前所有的深度学习应用，都基于反向传播算法进行训练。</p><p>但是，我们人类的大脑是这样学习的吗？</p><p>诚然现在的神经科学还无法告诉我们真正的答案，但我们凭我们的常识想想，我们大脑真正的神经网络会需要这样先前向传播一下，再反向传播一下然后更新神经元？这未免太不“科学”了。直观的想象我们大脑的神经元应该都是单独的个体，通过与周围的神经元交流来改变自己。但是对于反向传播算法，这种方法最大的缺点就是更新速度。前面的神经元需要等着后面的神经网络传回误差数据才能更新，要是以后搞个10000+层的神经网络，这显然就太慢了。所以，</p><p>能不能异步的更新参数？</p><p>甚至，每个参数能够同时更新？</p><p>或者差一点，只要前向传播一下就能更新参数？</p><p>这些问题要是能解决那就是game changing了。</p><p>那么现在DeepMind又开挂了，最新2016年8月18号出来的问题第一次解决了上面的问题。</p><p>文章题目：Decoupled Neural Interfaces using Synthetic Gradients </p><p>文章链接：<a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1608.05343.pdf\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">arxiv.org/pdf/1608.0534</span><span class=\"invisible\">3.pdf</span><span class=\"ellipsis\"></span><i class=\"icon-external\"></i></a> （本文图片都引用自文章）</p><h2>2 What is the idea?</h2><p>如果我们陷入在反向传播的思维中，我们就完全无法想象如果没有从后面传回来梯度误差，我们该怎么更新参数。DeepMind打破这种思路，如果不传回来，我们可以</p><p><b>合成梯度！也就是Synthetic Gradients！</b></p><p>也就是我们可以预测梯度。如果我们预测得准确，那么就可以直接更新了。</p><p><img src=\"http://pic1.zhimg.com/6bd8df82a8791c6e437263668d21b4e4_b.png\" data-rawwidth=\"1990\" data-rawheight=\"752\" class=\"origin_image zh-lightbox-thumb\" width=\"1990\" data-original=\"http://pic1.zhimg.com/6bd8df82a8791c6e437263668d21b4e4_r.png\">看上图，一般的反向传播如图b所示，从后到前依次传递梯度（绿色的线），然后更新参数。那么这里，我们使用一个M来预测梯度（蓝色的线），然后更新参数。我们传给M当前层的输出，然后M返回给我们梯度。</p><p>那么怎么预测梯度？</p><p><b>就用神经网络来预测！</b></p><p><b>也就是每一层的神经网络对应另一个神经网络M，每个M来调控每一层的神经网络更新！</b></p><p><b>这套方法称为 Decoupled Neural Interfaces(DNI), 也就是将神经网络分解训练的意思。</b></p><p>那么不管是MLP，CNN还是RNN或者其他各种结构的神经网络，因为都是以层为单位，都可以使用神经网络来合成梯度，也就是都可以使用这样的方法来实现训练。</p><h2>3 合成梯度的M神经网络是如何训练的？</h2><p><img src=\"http://pic2.zhimg.com/7223b3b3fd0b96029c8044ade57b5f0d_b.png\" data-rawwidth=\"1778\" data-rawheight=\"702\" class=\"origin_image zh-lightbox-thumb\" width=\"1778\" data-original=\"http://pic2.zhimg.com/7223b3b3fd0b96029c8044ade57b5f0d_r.png\">合成梯度的M神经网络用来输出估计的梯度误差。那么要训练M就需要有一个梯度误差来做目标，但是这里没有完全的反向传播，如何得到真实的梯度误差？作者采用一个tradeoff，利用下一层神经网络的估计梯度误差来计算本层的梯度误差，并利用这个误差作为目标训练M。如上图所示，<img src=\"http://www.zhihu.com/equation?tex=f_i\" alt=\"f_i\" eeimg=\"1\">输出<img src=\"http://www.zhihu.com/equation?tex=h_i\" alt=\"h_i\" eeimg=\"1\">到<img src=\"http://www.zhihu.com/equation?tex=M_%7Bi%2B1%7D\" alt=\"M_{i+1}\" eeimg=\"1\">，然后<img src=\"http://www.zhihu.com/equation?tex=M_%7Bi%2B1%7D\" alt=\"M_{i+1}\" eeimg=\"1\">输出估计的梯度误差<img src=\"http://www.zhihu.com/equation?tex=%5Chat%7B%5Cdelta_i%7D\" alt=\"\\hat{\\delta_i}\" eeimg=\"1\">，接下来利用<img src=\"http://www.zhihu.com/equation?tex=%5Chat%7B%5Cdelta_i%7D\" alt=\"\\hat{\\delta_i}\" eeimg=\"1\">来更新<img src=\"http://www.zhihu.com/equation?tex=f_i\" alt=\"f_i\" eeimg=\"1\">的参数。接下来<img src=\"http://www.zhihu.com/equation?tex=h_i\" alt=\"h_i\" eeimg=\"1\">输入到下一层神经网络<img src=\"http://www.zhihu.com/equation?tex=f_%7Bi%2B1%7D\" alt=\"f_{i+1}\" eeimg=\"1\">中，同理得到该层的估计梯度误差<img src=\"http://www.zhihu.com/equation?tex=%5Chat%7B%5Cdelta%7D_%7Bi%2B1%7D\" alt=\"\\hat{\\delta}_{i+1}\" eeimg=\"1\">，然后利用<img src=\"http://www.zhihu.com/equation?tex=%5Chat%7B%5Cdelta%7D_%7Bi%2B1%7D\" alt=\"\\hat{\\delta}_{i+1}\" eeimg=\"1\">通过<img src=\"http://www.zhihu.com/equation?tex=%5Cdelta_i+%3D+f%5E%60_%7Bi%2B1%7D%28h_i%29%5Chat%7B%5Cdelta%7D_%7Bi%2B1%7D\" alt=\"\\delta_i = f^`_{i+1}(h_i)\\hat{\\delta}_{i+1}\" eeimg=\"1\">也就是i+1层的梯度乘以梯度误差从而得到i层的梯度误差<img src=\"http://www.zhihu.com/equation?tex=%5Cdelta_i\" alt=\"\\delta_i\" eeimg=\"1\">,然后就可以使用<img src=\"http://www.zhihu.com/equation?tex=%5Cdelta_i\" alt=\"\\delta_i\" eeimg=\"1\">更新M了。所以M神经网络的训练需要BP。</p><h2>4 看结果</h2><p><img src=\"http://pic3.zhimg.com/c9edd09e655b6baa1aaa49025b146992_b.png\" data-rawwidth=\"1956\" data-rawheight=\"876\" class=\"origin_image zh-lightbox-thumb\" width=\"1956\" data-original=\"http://pic3.zhimg.com/c9edd09e655b6baa1aaa49025b146992_r.png\">上图是MNIST的训练，采用全连接网络FCN或者CNN进行训练。从结果上可以看到，DNI特别是cDNI（就是将数据的标签作为神经网络M的输入）效果蛮好的（略低于反向传播），但是训练速度比原来采用反向传播的快，特别看上面的曲线橙色部分，比灰色的反向传播快了非常多。</p><p><img src=\"http://pic4.zhimg.com/91fc6553e5d87aac17561dc550beffcb_b.png\" data-rawwidth=\"2046\" data-rawheight=\"774\" class=\"origin_image zh-lightbox-thumb\" width=\"2046\" data-original=\"http://pic4.zhimg.com/91fc6553e5d87aac17561dc550beffcb_r.png\">上面这图是针对RNN的训练，一个是Repeat Copy复制任务，一个是语言模型的训练。因为RNN的梯度计算面临无穷的循环，所以一般采用一定的时间间隔来计算梯度。那么这里，DNI的效果远远超过了BPTT（Back Propagation Through Time). 速度两倍以上。</p><p>从上面的结果可以看出，采用DNI进行训练相比反向传播竟然速度快，效果好。要是预测梯度的神经网络能提前训练好，估计又能快不少吧！</p><h2>5 One More Thing</h2><p>DeepMind不仅仅做到不需要反向传播，甚至更进一步，连前向传播也不用，直接异步更新每一层的参数。怎么做的？</p><p><b>不仅仅预测梯度，我们还预测输入！</b></p><p><img src=\"http://pic3.zhimg.com/8826d3fcd18e292a08ddb3b84202649a_b.png\" data-rawwidth=\"1996\" data-rawheight=\"566\" class=\"origin_image zh-lightbox-thumb\" width=\"1996\" data-original=\"http://pic3.zhimg.com/8826d3fcd18e292a08ddb3b84202649a_r.png\">上图的I是每一层的输入预测神经网络，用来预测上一层的输出。</p><p>这样做对于MNIST的训练也能达到2%的误差，只是慢了一点。估计主要的慢是在I和M的模型训练上。这里4层隐藏层就有6个额外的神经网络了。</p><h2>6 这个成果意味着什么？</h2><p><b>神经网络模块化了</b></p><p>每一层网络都可以看成独立的一个模块，模块与模块之间相互通信，从而实现学习。而学习训练不再需要同步，可以异步。也就是说每个模块都可以独立训练。Paper中也做了异步训练的实验，可以随机的训练神经网络中的不同层，或者有两个神经网络需要相互配合的，都可以异步训练。这是这个成果最大的意义，将能够因此构建出完全不一样的神经网络模型，训练方式发生完全的改变。</p><h2>7 存在的问题</h2><p>大家都可以注意到，虽然这个idea能够使主神经网络不再使用反向传播算法，<b>但是I和M的神经网络都是依靠反向传播算法进行更新！也就是反而多了好多个小的神经网络。</b>但是这个方法如果不考虑I和M（主要是M）的训练，那么显然将会非常的快。那么，I比较难，涉及到具体的输入，但是有没有可能能够预训练M呢？或者换一个角度思考，我们人类大脑的神经元是否是相互独立，每一个神经元都有自己的一套学习机制在里面，能够自主改变？这些很值得我们思考。</p><h2>8 一点感想</h2><p>因为神经网络什么都能学习，所以用神经网络来更新神经网络也不足为怪。之前的<a href=\"https://zhuanlan.zhihu.com/p/21362413?refer=intelligentunit\" class=\"internal\">最前沿：让计算机学会学习Let Computers Learn to Learn - 智能单元 - 知乎专栏</a>就是使用神经网络来做梯度更新的工作。这里是使用神经网络来合成梯度。所以，如果把上一篇的成果结合进来，神经网络大部分都是神经网络自己在训练了！</p><blockquote><b>这是深度学习基本学习机制的大变革，一步一步迈向人类的大脑！<br></b></blockquote><p>补充：DeepMind官网给出了一个介绍DNI的博客：<a href=\"http://link.zhihu.com/?target=https%3A//deepmind.com/blog%23decoupled-neural-interfaces-using-synthetic-gradients\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"><span class=\"invisible\">https://</span><span class=\"visible\">deepmind.com/blog#</span><span class=\"invisible\">decoupled-neural-interfaces-using-synthetic-gradients</span><span class=\"ellipsis\"></span><i class=\"icon-external\"></i></a></p><h2>版权声明：本文为原创文章，未经允许不得转载！</h2>","state":"published","sourceUrl":"","pageCommentsCount":0,"canComment":true,"snapshotUrl":"","slug":22143664,"publishedTime":"2016-08-27T15:59:24+08:00","url":"/p/22143664","title":"最前沿：深度学习训练方法大革新，反向传播训练不再唯一","summary":"1 前言众所周知，在深度学习中我们使用反向传播算法进行训练。可能在任意一门深度学习课程中，反向传播都是必学的内容。我们使用反向传播计算每个参数的梯度，从而能够使用各种梯度下降方法SGD，Adam，RMSProp等来更新参数。基本上可以说反向传播算法是深度…","reviewingCommentsCount":0,"meta":{"previous":null,"next":null},"commentPermission":"anyone","commentsCount":0,"likesCount":0}},"annotationDetail":null,"commentsCount":157,"likesCount":1071,"FULLINFO":true}},"User":{"wu-yan-ri-35":{"isFollowed":false,"name":"无烟日","headline":"","avatarUrl":"https://pic2.zhimg.com/f90615bea58600b4b54c96b83206b1b5_s.jpg","isFollowing":false,"type":"people","slug":"wu-yan-ri-35","bio":"文盲","hash":"d0eb20f01e68a88a414562113950eef9","uid":642332238319194100,"links":{"columns":"/api/me/columns"},"isOrg":false,"pendingColumns":[],"activated":true,"allowShareDaily":false,"isBindPhone":true,"mutedInfo":{"muted":false,"reason":null},"description":"","muted":false,"profileUrl":"https://www.zhihu.com/people/wu-yan-ri-35","avatar":{"id":"f90615bea58600b4b54c96b83206b1b5","template":"https://pic2.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false,"email":null,"columns":[]},"du-ke":{"isFollowed":false,"name":"杜客","headline":"研究增强学习。积累学习方法论，实践健身训练体系。专栏：https://zhuanlan.zhihu.com/intelligentunit","avatarUrl":"https://pic2.zhimg.com/5ab5b93bd_s.jpg","isFollowing":false,"type":"people","slug":"du-ke","bio":"CS231n资源在专栏文章中","hash":"928affb05b0b70a2c12e109d63b6bae5","uid":27591822016512,"isOrg":false,"description":"研究增强学习。积累学习方法论，实践健身训练体系。专栏：https://zhuanlan.zhihu.com/intelligentunit","profileUrl":"https://www.zhihu.com/people/du-ke","avatar":{"id":"5ab5b93bd","template":"https://pic2.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false,"badge":{"identity":null,"bestAnswerer":null}},"li-yi-ying-73":{"bio":"软件工程软妹子、徒步登山女汉子","isFollowing":false,"hash":"f11e78650e8185db2b013af42fd9a481","uid":714373748634964000,"isOrg":false,"slug":"li-yi-ying-73","isFollowed":false,"description":"研究机器学习、机器人、云平台架构；户外爱好者、阅读小美女－－精神和身体总有一个在路上！","name":"李艺颖","profileUrl":"https://www.zhihu.com/people/li-yi-ying-73","avatar":{"id":"68f05e262fb914cd3402eb9d30143df8","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},"kun-kun-97-81":{"bio":null,"isFollowing":false,"hash":"e7fcc05b0cf8a90a3e676d0206f888c9","uid":30261639118848,"isOrg":false,"slug":"kun-kun-97-81","isFollowed":false,"description":"读作kunkun","name":"堃堃","profileUrl":"https://www.zhihu.com/people/kun-kun-97-81","avatar":{"id":"56c592f12","template":"https://pic3.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},"sqfan":{"bio":"BigData Processing, M.Sc Candidate @NJU","isFollowing":false,"hash":"584f06e4ed2edc6007e4793179e7cdc1","uid":28914034409472,"isOrg":false,"slug":"sqfan","isFollowed":false,"description":"https://cn.linkedin.com/in/shiqing-fan-a7b320103","name":"ShiqingFan","profileUrl":"https://www.zhihu.com/people/sqfan","avatar":{"id":"47e5cf142df73b860fdd0a89be22b778","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false},"hmonkey":{"bio":"学生","isFollowing":false,"hash":"77a6055b8d73148aee3464cf7a3b8d09","uid":557306122193793000,"isOrg":false,"slug":"hmonkey","isFollowed":false,"description":"机器学习\\深度学习方向初学者","name":"猴子","profileUrl":"https://www.zhihu.com/people/hmonkey","avatar":{"id":"f0c45ebc982d64ea0c4822517e7285ac","template":"https://pic1.zhimg.com/{id}_{size}.jpg"},"isOrgWhiteList":false}},"Comment":{},"favlists":{}},"me":{"slug":"wu-yan-ri-35"},"global":{},"columns":{"intelligentunit":{"following":true,"canManage":false,"href":"/api/columns/intelligentunit","name":"智能单元","creator":{"slug":"du-ke"},"url":"/intelligentunit","slug":"intelligentunit","avatar":{"id":"4a97d93d652f45ededf2ebab9a13f22b","template":"https://pic4.zhimg.com/{id}_{size}.jpeg"}}},"columnPosts":{},"postComments":{},"postReviewComments":{"comments":[],"newComments":[],"hasMore":true},"favlistsByUser":{},"favlistRelations":{},"promotions":{},"switches":{"couldAddVideo":false},"draft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null}},"drafts":{"draftsList":[]},"config":{"userNotBindPhoneTipString":{}},"recommendPosts":{"articleRecommendations":[],"columnRecommendations":[]},"env":{"isAppView":false,"appViewConfig":{"content_padding_top":128,"content_padding_bottom":56,"content_padding_left":16,"content_padding_right":16,"title_font_size":22,"body_font_size":16,"is_dark_theme":false,"can_auto_load_image":true,"app_info":"OS=iOS"},"isApp":false},"sys":{}}</textarea>

    
    <script src="//static.zhihu.com/hemingway/common.881f21297fcfd9990feb.js"></script>
<script src="//static.zhihu.com/hemingway/app.3f4b9085afff6f28cd02.js"></script>
<script src="//static.zhihu.com/hemingway/raven.b1fbad740f1451a136fb.js" async defer></script>
  </body>
</html>
